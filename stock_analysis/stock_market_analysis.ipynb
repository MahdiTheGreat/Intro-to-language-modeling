{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'pmdarima,'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\ANv\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima, transformers, yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANv\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks based on Market Reputation and Company Size can be divided to:\n",
    "a) Blue-Chip Stocks\n",
    "\n",
    "    Definition: Stocks of large, well-established, and financially stable companies with a history of reliable performance.\n",
    "    Examples: Apple, Microsoft, Coca-Cola.\n",
    "    Key Features:\n",
    "        Considered low-risk investments.\n",
    "        Often pay consistent dividends.\n",
    "        Suitable for long-term, stable growth.\n",
    "\n",
    "b) Penny Stocks\n",
    "\n",
    "    Definition: Stocks of small companies that trade at very low prices, usually below $5 per share.\n",
    "    Key Features:\n",
    "        High-risk and speculative.\n",
    "        Low market capitalization.\n",
    "        Often traded over-the-counter (OTC).\n",
    "\n",
    "c) Growth Stocks\n",
    "\n",
    "    Definition: Stocks of companies expected to grow at a rate higher than the market average.\n",
    "    Key Features:\n",
    "        Usually reinvest earnings into growth (rarely pay dividends).\n",
    "        High potential for capital appreciation.\n",
    "        Often more volatile.\n",
    "\n",
    "d) Value Stocks\n",
    "\n",
    "    Definition: Stocks that are considered undervalued compared to their intrinsic value.\n",
    "    Key Features:\n",
    "        Low price-to-earnings (P/E) ratios.\n",
    "        May pay dividends.\n",
    "        Attractive to long-term investors.\n",
    "\n",
    "Since penny stocks are highly volatile and succeptable to market manipulation and value stocks are based on subjective opinion, for evaluation we use Blue chip and Growth stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tickers: 20\n"
     ]
    }
   ],
   "source": [
    "blue_chip_stocks = [\"AAPL\",\"MSFT\",\"KO\",\"PG\",\"JNJ\",\"DIS\",\"WMT\",\"JPM\",\"MCD\",\"GE\"]\n",
    "Growth_stocks = [\"TSLA\",\"AMZN\",\"NVDA\",\"GOOG\",\"META\",\"NFLX\",\"SHOP\",\"SQ\",\"CRM\",\"UBER\"]\n",
    "print(\"Number of tickers:\", len(blue_chip_stocks)+len(Growth_stocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Ticker News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(company_string):\n",
    "    \"\"\"\n",
    "    Extracts the main company name from a given string by removing common suffixes.\n",
    "\n",
    "    Parameters:\n",
    "        company_string (str): The full company name string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned company name.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to match common suffixes\n",
    "    pattern = r\",?\\s+(Inc\\.|Incorporated|Corp\\.|Corporation|Ltd\\.|Limited|LLC|LLP|P\\.L\\.C\\.|Co\\.|Company|Group|Holdings)$\"\n",
    "    \n",
    "    # Remove the suffix from the company name\n",
    "    company_name = re.sub(pattern, \"\", company_string, flags=re.IGNORECASE)\n",
    "    \n",
    "    return company_name.strip()\n",
    "\n",
    "def get_news_sentiment(API_KEY='C2ARQRXUKFAUTVP1', tickers=None, topics=None, limit=None, sort_by='LATEST',\n",
    "start_date=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch news and sentiment data from Alpha Vantage.\n",
    "\n",
    "    Parameters:\n",
    "        tickers (str): Comma-separated tickers (e.g., \"AAPL,MSFT\").\n",
    "        topics (str): Topics of interest (e.g., \"technology,finance\").\n",
    "        limit (int): Number of news articles to retrieve.\n",
    "        sort_by (str): Sort order: 'LATEST', 'RELEVANCE', or 'EARLIEST'.\n",
    "\n",
    "    Returns:\n",
    "        list: News articles with metadata.\n",
    "    \"\"\"\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"apikey\": API_KEY,\n",
    "        \"tickers\": tickers,\n",
    "        \"topics\": topics,\n",
    "        \"limit\": limit,\n",
    "        \"sort_by\": sort_by,\n",
    "        \"time_from\": start_date,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        if \"feed\" in data:\n",
    "            return data[\"feed\"]\n",
    "        else:\n",
    "            print(\"No news data available.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return []\n",
    "\n",
    "def get_raw_news(ticker, interval=\"1y\"):\n",
    "    \"\"\"\n",
    "    Get raw news data for a specific ticker and interval and saves it in raw_data folder.\n",
    "\n",
    "    Parameters:\n",
    "        interval (str): Specifies how long ago the news should be fetched. Should be one of (\"1w\", \"1m\", \"1y\").\n",
    "        ticker (str): Name of ticker\n",
    "\n",
    "    Returns:\n",
    "        list: None.\n",
    "    \"\"\"\n",
    "\n",
    "    if interval == \"1w\":\n",
    "        start_date = datetime.today() - timedelta(days=7)\n",
    "        start_date = start_date.strftime('%Y%m%dT%H%M')\n",
    "    elif interval == \"1m\":\n",
    "        start_date = datetime.today() - timedelta(days=31)\n",
    "        start_date = start_date.strftime('%Y%m%dT%H%M')\n",
    "    elif interval == \"1y\":\n",
    "        start_date = datetime.today() - timedelta(days=365)\n",
    "        start_date = start_date.strftime('%Y%m%dT%H%M')\n",
    "\n",
    "    else:\n",
    "        start_date = None\n",
    "\n",
    "    news = get_news_sentiment(tickers=ticker, start_date=start_date)\n",
    "    data = {\n",
    "        \"title\": [],\n",
    "        \"published\": [],\n",
    "        \"source\": [],\n",
    "        \"summary\": [],\n",
    "        \"sentiment_label\": [],\n",
    "        \"sentiment_score\": [],\n",
    "        \"relevance_score\": []\n",
    "    }\n",
    "\n",
    "    if news: # If the query recieved any news\n",
    "        \n",
    "        for article in news:\n",
    "            \n",
    "            ticker_sentiment = article['ticker_sentiment']\n",
    "            for i, sentiment in enumerate(ticker_sentiment):\n",
    "                ticker_idx = i\n",
    "                data['title'].append(article['title'])\n",
    "                data['published'].append(article['time_published'])\n",
    "                data['summary'].append(article['summary'])\n",
    "                data['source'].append(article['source'])\n",
    "                data['sentiment_label'].append(ticker_sentiment[ticker_idx]['ticker_sentiment_label'])\n",
    "                data['sentiment_score'].append(ticker_sentiment[ticker_idx]['ticker_sentiment_score'])\n",
    "                data['relevance_score'].append(ticker_sentiment[ticker_idx]['relevance_score'])\n",
    "\n",
    "    # Convert to pandas dataframe and save as csv\n",
    "    ticker_df = pd.DataFrame(data)\n",
    "    # Check if the folder exists\n",
    "    folder_name = \"raw_data\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        # Create the folder\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # File name and path\n",
    "    file_name = f\"{str(ticker).lower()}_raw.csv\"\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "    ticker_df.to_csv(file_path)\n",
    "\n",
    "def filter_news(ticker, relevance_score_threshold=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Filter a DataFrame from a CSV file if it exists in the 'raw_data' folder. Also removes duplicates and keeps the one with highest relevance score.\n",
    "    \n",
    "    Parameters:\n",
    "        ticker (str): Ticker symbol of the stock.\n",
    "        relevance_score_threshold (float): What is the minimum relevance score to be able to qualify as news.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the raw data CSV file does not exist.\n",
    "    \"\"\"\n",
    "    file_path = f\"raw_data/{str(ticker).lower()}_raw.csv\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file '{file_path}' does not exist in the 'raw_data' folder.\")\n",
    "    \n",
    "    # Fetch stock information\n",
    "    stock = yf.Ticker(ticker)\n",
    "    summary = stock.info\n",
    "\n",
    "    comp_name = extract_company_name(summary['longName'])\n",
    "\n",
    "    # Load the CSV into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop duplicates by keeping the one with the highest relevance score\n",
    "    df_unique = df.loc[df.groupby(\"title\")[\"relevance_score\"].idxmax()]\n",
    "\n",
    "    # Reset index for clean presentation\n",
    "    df_unique = df_unique.reset_index(drop=True)\n",
    "\n",
    "    # Apply filtering\n",
    "    new_df = df[df['relevance_score'] > relevance_score_threshold]\n",
    "\n",
    "    return new_df, comp_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Company Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arima_forecast(data):\n",
    "    warnings.filterwarnings(\"ignore\") # Suppress warnings\n",
    "    \n",
    "    arima_model = auto_arima(pd.Series(data['Close']))\n",
    "    forecast = arima_model.predict(n_periods=len(data)//4) \n",
    "\n",
    "    if forecast.iloc[-1] > forecast.iloc[0]:\n",
    "        arima_forecast = \"increase\"\n",
    "    elif forecast.iloc[-1] < forecast.iloc[0]:\n",
    "        arima_forecast = \"decrease\"\n",
    "    else:\n",
    "        arima_forecast = None\n",
    "\n",
    "    if arima_forecast:\n",
    "        return f\" An ARIMA model fit on the data predicts that the stock's price will {arima_forecast}.\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def detect_trend(data, ticker):\n",
    "    \"\"\"\n",
    "    Detects and categorizes the trend of a stock over the past year using a generalized method.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "\n",
    "    Returns:\n",
    "        str: Natural language summary of the trend.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare data for regression\n",
    "    data['Days'] = (data.index - data.index[0]).days\n",
    "    X = data['Days'].values.reshape(-1, 1)\n",
    "    y = data['Close'].values\n",
    "\n",
    "    # Fit a linear regression model for the entire dataset\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    overall_slope = model.coef_[0]\n",
    "\n",
    "    # Dynamically calculate slopes for all possible sub-periods\n",
    "    n = len(y)\n",
    "    window_sizes = range(5, max(5, n // 4))  # Use a range of window sizes (5 to 25% of the dataset length)\n",
    "    slopes = []\n",
    "\n",
    "    for window in window_sizes:\n",
    "        for i in range(n - window):\n",
    "            X_window = X[i:i + window]\n",
    "            y_window = y[i:i + window]\n",
    "            model.fit(X_window, y_window)\n",
    "            slopes.append(model.coef_[0])\n",
    "\n",
    "    # Calculate percentiles dynamically\n",
    "    slope_percentiles = np.percentile(slopes, [25, 50, 75])  # Quartiles\n",
    "\n",
    "    # Dynamically categorize trend based on the overall slope\n",
    "    if overall_slope > slope_percentiles[2]:  # Above 75th percentile\n",
    "        trend_category = \"a strong upward trend\"\n",
    "    elif slope_percentiles[1] <= overall_slope <= slope_percentiles[2]:  # Between median and 75th percentile\n",
    "        trend_category = \"a moderate upward trend\"\n",
    "    elif slope_percentiles[0] <= overall_slope < slope_percentiles[1]:  # Between 25th percentile and median\n",
    "        trend_category = \"a stable or sideways trend\"\n",
    "    else:  # Below 25th percentile\n",
    "        trend_category = \"a downward trend\"\n",
    "\n",
    "    # Create a natural language summary\n",
    "    summary = (\n",
    "        f\"Over the past year, {ticker} exhibited {trend_category}. \"\n",
    "        f\"The overall trend slope was approximately {overall_slope:.4f}.\"\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def stock_info_to_text(ticker):\n",
    "    \"\"\"\n",
    "    Converts Yahoo Finance stock information into qualitative text with generalized thresholds.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "\n",
    "    Returns:\n",
    "        str: A qualitative text summary of the stock.\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    info = stock.info\n",
    "\n",
    "    if not info:\n",
    "        return f\"No information available for {ticker}.\"\n",
    "\n",
    "    # Extract relevant information\n",
    "    name = info.get(\"longName\", ticker)\n",
    "    sector = info.get(\"sector\", \"N/A\")\n",
    "    industry = info.get(\"industry\", \"N/A\")\n",
    "    market_cap = info.get(\"marketCap\", None)\n",
    "    pe_ratio = info.get(\"trailingPE\", None)\n",
    "    dividend_yield = info.get(\"dividendYield\", None)\n",
    "    fifty_two_week_high = info.get(\"fiftyTwoWeekHigh\", None)\n",
    "    fifty_two_week_low = info.get(\"fiftyTwoWeekLow\", None)\n",
    "    current_price = info.get(\"regularMarketPrice\", None)\n",
    "\n",
    "    # Generalized thresholds for market cap\n",
    "    if market_cap:\n",
    "        if market_cap > 50e9:\n",
    "            market_cap_text = \"a large-cap company\"\n",
    "        elif market_cap > 2e9:\n",
    "            market_cap_text = \"a mid-cap company\"\n",
    "        else:\n",
    "            market_cap_text = \"a small-cap company\"\n",
    "    else:\n",
    "        market_cap_text = \"an unknown-cap company\"\n",
    "\n",
    "    # Generalized thresholds for PE ratio using percentiles\n",
    "    pe_description = \"N/A\"\n",
    "    if pe_ratio:\n",
    "        pe_percentiles = np.percentile([10, 15, 25, 40], [25, 50, 75])  # Hypothetical PE ranges\n",
    "        if pe_ratio < pe_percentiles[0]:\n",
    "            pe_description = \"undervalued\"\n",
    "        elif pe_ratio < pe_percentiles[1]:\n",
    "            pe_description = \"fairly valued\"\n",
    "        elif pe_ratio < pe_percentiles[2]:\n",
    "            pe_description = \"slightly overvalued\"\n",
    "        else:\n",
    "            pe_description = \"highly overvalued\"\n",
    "\n",
    "    pe_ratio_text = (\n",
    "        f\"The stock has a price-to-earnings (PE) ratio of {pe_ratio:.2f}, indicating it is {pe_description}.\"\n",
    "        if pe_ratio else\n",
    "        \"The PE ratio is unavailable.\"\n",
    "    )\n",
    "\n",
    "    # Generalized thresholds for dividend yield using percentiles\n",
    "    if dividend_yield:\n",
    "        if dividend_yield > 0.03:  # Example threshold for high yield\n",
    "            dividend_text = f\"The stock offers a high dividend yield of {dividend_yield * 100:.2f}%, appealing to income investors.\"\n",
    "        else:\n",
    "            dividend_text = f\"The stock offers a dividend yield of {dividend_yield * 100:.2f}%, which is modest.\"\n",
    "    else:\n",
    "        dividend_text = \"The stock does not currently pay dividends.\"\n",
    "\n",
    "    \n",
    "    # Fetch historical data\n",
    "    end_date = datetime.today()\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "    data = stock.history(start=start_date, end=end_date)\n",
    "    beta_value = stock.info.get(\"beta\")\n",
    "    \n",
    "    trend=detect_trend(data, ticker)\n",
    "\n",
    "    # Interpret beta for volatility\n",
    "    if beta_value > 1.2:\n",
    "        volatility_description = \"highly volatile compared to the market\"\n",
    "    elif 0.8 <= beta_value <= 1.2:\n",
    "        volatility_description = \"as volatile as the market\"\n",
    "    else:\n",
    "        volatility_description = \"less volatile than the market\"\n",
    "\n",
    "    if data.empty:\n",
    "        return f\"No price data available for {ticker}.\"\n",
    "\n",
    "    # Calculate metrics\n",
    "    start_price = data['Close'].iloc[0]\n",
    "    end_price = data['Close'].iloc[-1]\n",
    "    annual_return = ((end_price - start_price) / start_price) * 100\n",
    "    daily_returns = data['Close'].pct_change()\n",
    "    max_price = data['Close'].max()\n",
    "    min_price = data['Close'].min()\n",
    "    max_drawdown = ((min_price - max_price) / max_price) * 100\n",
    "\n",
    "    if current_price is None:\n",
    "        current_price = data['Close'].iloc[-1]\n",
    "\n",
    "    price_range_mid = (max_price + min_price) / 2\n",
    "    price_range = max_price - min_price\n",
    "    if current_price > (price_range_mid + price_range / 4):\n",
    "        price_range_text = \"near its yearly high\"\n",
    "    elif current_price < (price_range_mid - price_range / 4):\n",
    "        price_range_text = \"near its yearly low\"\n",
    "    else:\n",
    "        price_range_text = \"in the mid-range of its yearly performance\"\n",
    "    price_range_text = (\n",
    "        f\"Over the last year, the stock traded between ${fifty_two_week_low:.2f} and ${fifty_two_week_high:.2f}. \"\n",
    "        f\"The current price is ${current_price:.2f}, which is {price_range_text}.\"\n",
    "    )\n",
    "\n",
    "    # Statistical thresholds (quartiles)\n",
    "    return_percentiles = np.percentile(daily_returns.dropna(), [25, 50, 75])\n",
    "\n",
    "    # Qualitative analysis of annual return\n",
    "    if annual_return > return_percentiles[2]:\n",
    "        performance = \"strong growth\"\n",
    "    elif return_percentiles[1] <= annual_return <= return_percentiles[2]:\n",
    "        performance = \"moderate growth\"\n",
    "    elif return_percentiles[0] <= annual_return < return_percentiles[1]:\n",
    "        performance = \"stable performance\"\n",
    "    else:\n",
    "        performance = \"a decline\"\n",
    "\n",
    "    # Construct the summary\n",
    "    summary = (\n",
    "        f\"{name} operates in the {sector} sector and the {industry} industry. It is {market_cap_text}. \"\n",
    "        f\"{pe_ratio_text} {dividend_text} {price_range_text}\"\n",
    "        f\"Over the past year, {ticker} showed {performance}, \"\n",
    "        f\"with an annual return of approximately {annual_return:.2f}%. \"\n",
    "        f\"The stock was {volatility_description}, \"\n",
    "        f\"with a maximum price of ${max_price:.2f} and a minimum price of ${min_price:.2f}. \"\n",
    "        f\"The largest drop during the year was {abs(max_drawdown):.2f}%, indicating the stock's maximum drawdown. \"\n",
    "    )\n",
    "\n",
    "    # Add trend if available\n",
    "    if trend != \"no trend\":\n",
    "        summary += f\"{trend}\"\n",
    "\n",
    "    # Add ARIMA forecast if available\n",
    "    arima_forecast = get_arima_forecast(data)\n",
    "    if arima_forecast:\n",
    "        summary += arima_forecast\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Sentiment Analysis Using FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(number, range_tuple):\n",
    "    \"\"\"\n",
    "    Checks if a number is within a range defined by a tuple.\n",
    "\n",
    "    Args:\n",
    "        number (float): The number to check.\n",
    "        range_tuple (tuple): A tuple containing two numbers (start, end) defining the range.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the number is within the range, False otherwise.\n",
    "    \"\"\"\n",
    "    start, end = range_tuple\n",
    "    return start <= number <= end\n",
    "\n",
    "def compute_weighted_average(sentiment_scores, relevance_scores):\n",
    "    \"\"\"\n",
    "    Computes the weighted average of sentiment scores using relevance scores as weights.\n",
    "    \n",
    "    Args:\n",
    "        sentiments (list): List of sentiment labels (\"Positive\", \"Neutral\", \"Negative\").\n",
    "        relevance_scores (list): List of relevance scores (weights) for each sentiment.\n",
    "        \n",
    "    Returns:\n",
    "        float: The weighted average sentiment score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_sum = sum(score * weight for score, weight in zip(sentiment_scores, relevance_scores))\n",
    "    total_weights = sum(relevance_scores)\n",
    "    \n",
    "    return weighted_sum / total_weights if total_weights > 0 else 0\n",
    "\n",
    "# Function to analyze sentiment\n",
    "def analyze_sentiment(news_df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a list of texts using FinBERT.\n",
    "    Args:\n",
    "        news_df (DataFrame): Pandas DataFrame with all relevant news articles and their summaries.\n",
    "    Returns:\n",
    "        sentiment (str): The aggregated news sentiment (Positive, Slightly Positive, Neutral, Slightly Negative, Negative).\n",
    "    \"\"\"\n",
    "    sentiments = []\n",
    "    text_summaries = list(news_df['summary'])\n",
    "    relevance_scores = list(news_df['relevance_score'])\n",
    "\n",
    "    for text in text_summaries:\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        # Get predictions from the model\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "        predictions = torch.softmax(outputs.logits, dim=1)  # Convert logits to probabilities\n",
    " \n",
    "        # Get the label with the highest probability\n",
    "        label = torch.argmax(predictions, dim=1).item()\n",
    "        \n",
    "        # Map label to sentiment\n",
    "        if label == 0:\n",
    "            sentiments.append(-1)\n",
    "        elif label == 1:\n",
    "            sentiments.append(0)\n",
    "        elif label == 2:\n",
    "            sentiments.append(1)\n",
    "\n",
    "    weighted_average = compute_weighted_average(sentiments, relevance_scores)\n",
    "\n",
    "    thresholds = {\n",
    "        \"Negative\": (-1, -0.6),\n",
    "        \"Slightly Negative\": (-0.6, -0.2),\n",
    "        \"Neutral\": (-0.2, 0.2),\n",
    "        \"Slightly Positive\": (0.2, 0.6),\n",
    "        \"Positive\": (0.6, 1),\n",
    "    }\n",
    "\n",
    "    # Dynamically categorize trend based on the overall slope\n",
    "    for key, value in thresholds.items():\n",
    "        if in_range(weighted_average,value):\n",
    "            sentiment = key\n",
    "            break\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(ticker, model, tokenizer, include_rec=False):\n",
    "\n",
    "    # Check if ticker news exists in raw_news folder otherwise fetch raw news\n",
    "    file_path = f\"raw_data/{str(ticker).lower()}_raw.csv\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        get_raw_news(ticker, interval=\"1y\")\n",
    "    \n",
    "    news_df, comp_name = filter_news(ticker, relevance_score_threshold=0.7)\n",
    "    sentiment = analyze_sentiment(news_df, model, tokenizer)\n",
    "    company_summary = stock_info_to_text(ticker)\n",
    "\n",
    "    recommendations = yf.Ticker(ticker).get_recommendations()\n",
    "\n",
    "    sentiments = list(recommendations.keys())\n",
    "    \n",
    "    rec_first = recommendations.iloc[0, 1:]\n",
    "    weights=dict()\n",
    "    for key in rec_first.keys():\n",
    "        weights[key] = rec_first[key]/rec_first.sum()\n",
    "    \n",
    "    weights=list(weights.values())\n",
    "\n",
    "    mean_value=np.average(a=np.linspace(1,len(weights),len(weights)),weights=weights)\n",
    "    recommendation = sentiments[round(mean_value)]\n",
    "    print(\"Analyst recommendation:\",recommendation)\n",
    "    # Start with the company summary\n",
    "    prompt = (\n",
    "        \"You are a financial analyst. Your task is to analyze the given company summary, the sentiment of the latest news articles and analyst recommendation to decide whether the company's stock should be classified as 'Strong Buy', 'Buy', 'Hold', 'Sell' or 'Strong Sell'. \"\n",
    "        \"Provide a clear decision and a detailed explanation based on the information provided.\\n\\n\"\n",
    "        f\"The company name is {comp_name} and the ticker is {ticker}\\n\\n\"\n",
    "        f\"Company Summary: {company_summary}\\n\\n\" \n",
    "\n",
    "    )   \n",
    "    if include_rec:\n",
    "        f\"The majority of analysts give the sentiment: {recommendation}.\\n\\n\"\n",
    "\n",
    "    prompt += f\"The sentiment of the latest news articles was: {sentiment}.\\n\\n\"\n",
    "    prompt += \"Your response should include:\\n1. A decision: 'Strong Buy', 'Buy', 'Hold', 'Sell' or 'Strong Sell'.\\n2. A detailed explanation justifying your decision, citing specific points from the company summary and the articles.\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llama(model, tokenizer, ticker, system_prompt):\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(system_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate response\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=2048,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Decode and print the response\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    response = response[len(system_prompt):]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(response,ticker):\n",
    "    \n",
    "    weights=dict()\n",
    "    recommendations = yf.Ticker(ticker).get_recommendations()\n",
    "    \n",
    "    rec_first = recommendations.iloc[0, 1:]\n",
    "    \n",
    "    for key in rec_first.keys():\n",
    "        weights[key] = rec_first[key]/rec_first.sum()\n",
    "    \n",
    "    weights=list(weights.values())\n",
    "\n",
    "    mean_value=np.average(a=np.linspace(1,len(weights),len(weights)),weights=weights)\n",
    "\n",
    "    floor_value = np.floor(mean_value)\n",
    "    ceil_value = np.ceil(mean_value)\n",
    "    majority_value = np.argmax(weights)+1\n",
    "\n",
    "    # Find all start indices of the substring\n",
    "    possible_sentiments=['Strong Buy', 'Buy', 'Hold', 'Sell' ,'Strong Sell']\n",
    "    sentiment_location=[]\n",
    "    for substring in possible_sentiments:\n",
    "        matches = [match.start() for match in re.finditer(re.escape(substring), response, re.IGNORECASE)]\n",
    "        if len(matches) == 0:\n",
    "            sentiment_location.append(1000000000)\n",
    "        else:\n",
    "            sentiment_location.append(min(matches))\n",
    "                 \n",
    "    model_value = np.argmin(sentiment_location)+1\n",
    "    print(\"Model Sentiment:\", possible_sentiments[model_value-1])\n",
    "\n",
    "    if model_value == majority_value:\n",
    "        correct = True\n",
    "    \n",
    "    elif model_value in [floor_value, ceil_value]:\n",
    "        correct = True\n",
    "    \n",
    "    else:\n",
    "        correct = False\n",
    "\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load Llama 3.2 model and tokenizer\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"  # Replace with the model you have downloaded or hosted\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT model and tokenizer\n",
    "sentiment_model_name = \"yiyanghkust/finbert-tone\"\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: hold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "3. A recommendation for the investor.\n",
      "\n",
      "**Based on the analysis, my decision is: Sell**\n",
      "\n",
      "My detailed explanation is as follows:\n",
      "\n",
      "Firstly, the company's stock price is highly overvalued with a price-to-earnings (PE) ratio of 116.21. This high valuation indicates that the stock may be due for a correction, and selling now may be a prudent decision. Furthermore, the stock does not pay dividends, which may not provide any income for investors.\n",
      "\n",
      "Secondly, the stock has shown strong growth over the past year, but this growth is not sustainable in the long term. The stock's volatility is also a concern, with a maximum drop of 70.40% during the year. This volatility indicates that the stock may be susceptible to further price swings, which could negatively impact investor returns.\n",
      "\n",
      "Thirdly, the sentiment of the latest news articles is slightly negative, which suggests that investors may be losing confidence in the company. This negative sentiment could lead to a decline in the stock price, making it a good time to sell.\n",
      "\n",
      "Lastly, the overall trend slope of the stock is approximately 0.6154, which indicates a moderate upward trend. However, this trend is not strong enough to justify buying the stock at its current price.\n",
      "\n",
      "Based on these points, I recommend that investors sell their TSLA stocks now and consider investing in other stocks with more attractive valuations and growth prospects. This will help them minimize their exposure to the highly volatile stock and avoid potential losses.\n",
      "\n",
      "**Disclaimer:** The decision to buy or sell a stock should be based on individual investor goals and risk tolerance. This analysis is for informational purposes only and should not be considered as investment advice. Investors should consult with a financial advisor before making any investment decisions.**\n"
     ]
    }
   ],
   "source": [
    "# Sanity check; get single ticker response\n",
    "ticker = \"TSLA\"\n",
    "system_prompt = get_system_prompt(ticker, sentiment_model, sentiment_tokenizer, include_rec=True)\n",
    "response = run_llama(model, tokenizer, ticker, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy against analyst recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Ticker: MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Ticker: KO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Buy\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Strong Sell\n",
      "Correct: False\n",
      "Ticker: PG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Ticker: JNJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: DIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: WMT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: JPM\n",
      "No news data available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Ticker: MCD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Buy\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Buy\n",
      "Correct: True\n",
      "Ticker: GE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Strong Buy\n",
      "Correct: True\n",
      "Accuracy for ticker group blue_chip_stocks: 40.0 %\n",
      "Ticker: TSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: hold\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Strong Buy\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Strong Sell\n",
      "Correct: False\n",
      "Ticker: NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Buy\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Ticker: GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Ticker: META\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Strong Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: NFLX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Strong Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Ticker: SHOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Strong Buy\n",
      "Correct: False\n",
      "Ticker: SQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Ticker: CRM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: True\n",
      "Ticker: UBER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst recommendation: buy\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sentiment: Sell\n",
      "Correct: False\n",
      "Iteration 2\n",
      "Model Sentiment: Hold\n",
      "Correct: False\n",
      "Accuracy for ticker group growth_stocks: 10.0 %\n"
     ]
    }
   ],
   "source": [
    "ticker_groups=[blue_chip_stocks,Growth_stocks]\n",
    "ticker_group_names=[\"blue_chip_stocks\",\"growth_stocks\"]\n",
    "for t, ticker_group in enumerate(ticker_groups): # Run for each ticker group\n",
    "    corrects = 0\n",
    "    for ticker in ticker_group:\n",
    "        print(\"Ticker:\", ticker)\n",
    "        ticker_corrects = []\n",
    "        system_prompt = get_system_prompt(ticker, sentiment_model, sentiment_tokenizer)\n",
    "        for i in range(3): # Run three times for each ticker and get majority of corrects\n",
    "            print(\"Iteration\",i)\n",
    "            response = run_llama(model, tokenizer, ticker, system_prompt)\n",
    "            correct = evaluate(response, ticker)\n",
    "            print(\"Correct:\",correct)\n",
    "            #if not correct:\n",
    "            #    print(\"Response:\", response)\n",
    "            ticker_corrects.append(correct)\n",
    "\n",
    "        majority = True if ticker_corrects.count(True) > ticker_corrects.count(False) else False\n",
    "        \n",
    "        if majority:\n",
    "            corrects += 1\n",
    "    \n",
    "    print(f\"Accuracy for ticker group {ticker_group_names[t]}:\",round(corrects/len(ticker_groups[t]),3)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(corrects/len(ticker_groups[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
