{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Preparations"
      ],
      "metadata": {
        "id": "Ash16YV-b6T5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group 17: Jakob Svensson, Mahdi Afarideh, Maximilian Forsell"
      ],
      "metadata": {
        "id": "OWJbmNgzBECe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahdiTheGreat/Intro-to-language-modeling.git\n",
        "%cd Intro-to-language-modeling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXuQ-VlzuRv",
        "outputId": "98431c8e-03df-4d79-f8a2-4ae6d24914e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Intro-to-language-modeling'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 70 (delta 37), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (70/70), 31.81 MiB | 22.86 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/Intro-to-language-modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fv9gQcVafW3"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import nltk\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLeT6K6EDID5",
        "outputId": "42d47f2c-7d0c-4ba1-d4a6-1032a85d6340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=2024):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(1998)"
      ],
      "metadata": {
        "id": "Qjj4IdOi08ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot the training metrics\n",
        "\n",
        "def plot_training_metrics(train_acc, val_acc, train_loss, title, save_path):\n",
        "    # Ensure that all input lists have the same length\n",
        "    assert len(train_acc) == len(val_acc) == len(train_loss), \"All input histories must have the same length.\"\n",
        "\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "    # Create the metrics DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        'Epoch': epochs,\n",
        "        'Training Accuracy (%)': train_acc,\n",
        "        'Validation Accuracy (%)': val_acc,\n",
        "        'Training Loss': train_loss\n",
        "    })\n",
        "\n",
        "    # Initialize the plot\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Training and Validation Accuracy on ax1\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy (%)', color=color)\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Training Accuracy (%)'], label='Train Acc', color='tab:blue')\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Validation Accuracy (%)'], label='Val Acc', color='tab:cyan')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Create a second y-axis for Training Loss\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Loss', color=color)\n",
        "    ax2.plot(df_metrics['Epoch'], df_metrics['Training Loss'], label='Train Loss', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
        "\n",
        "    # Set plot title and layout\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and display the plot\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TDDGQTI51AF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDybdl906rv",
        "outputId": "2b2f0085-3986-4dad-c088-c89d47647860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 & 2"
      ],
      "metadata": {
        "id": "8VLcOGFvb-pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='lmdemo'\n",
        "zip_file = f\"{dataset}.zip\"\n",
        "!unzip -q $zip_file\n",
        "!rm $zip_file"
      ],
      "metadata": {
        "id": "IE8oAx8b3AWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set=open(f'{dataset}/train.txt','r',encoding='utf-8').read()\n",
        "val_set=open(f'{dataset}/val.txt','r',encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "clFRaGPQ4Jc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "class VocabularyBuilder:\n",
        "    def __init__(self, max_voc_size):\n",
        "        self.max_voc_size = max_voc_size\n",
        "        self.str_to_int = {}\n",
        "        self.int_to_str = {}\n",
        "        self.special_tokens = [\"BEGINNING\", \"END\", \"UNKNOWN\"]\n",
        "        self.token_counter = Counter()\n",
        "\n",
        "    def build_vocabulary(self, text):\n",
        "\n",
        "        sents=nltk.word_tokenize(text.lower())\n",
        "\n",
        "        for token in sents:\n",
        "            self.token_counter[token] += 1\n",
        "\n",
        "    def create_vocabulary(self):\n",
        "        for idx, token in enumerate(self.special_tokens):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        max_words = self.max_voc_size - len(self.special_tokens)\n",
        "        most_common_tokens = self.token_counter.most_common(max_words)\n",
        "\n",
        "        for idx, (token, _) in enumerate(most_common_tokens, start=len(self.special_tokens)):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "    def create_premade_vocabulary(self, c):\n",
        "        for idx, token in enumerate(self.special_tokens):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        max_words = self.max_voc_size - len(self.special_tokens)\n",
        "        most_common_tokens = c.most_common(max_words) # Here we can use a premade counter from a previous run\n",
        "\n",
        "        for idx, (token, _) in enumerate(most_common_tokens, start=len(self.special_tokens)):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "    def get_token_id(self, token):\n",
        "        return self.str_to_int.get(token.lower(), self.str_to_int[\"UNKNOWN\"])\n",
        "\n",
        "    def get_token_str(self, token_id):\n",
        "        return self.int_to_str.get(token_id, \"UNKNOWN\")\n",
        "\n",
        "    def sanity_check(self): # Here we run the sanity tests recommended in the assignment\n",
        "        assert len(self.str_to_int) <= self.max_voc_size, \"Vocabulary size exceeds max_voc_size.\"\n",
        "\n",
        "        for token in self.special_tokens:\n",
        "            assert token in self.str_to_int, f\"Missing special token: {token}\"\n",
        "\n",
        "        common_words = [\"the\", \"and\"]\n",
        "        rare_words = [\"cuboidal\", \"epiglottis\"]\n",
        "\n",
        "        for word in common_words:\n",
        "            assert word in self.str_to_int, f\"Common word '{word}' not in vocabulary.\"\n",
        "\n",
        "        for word in rare_words:\n",
        "            assert word not in self.str_to_int, f\"Rare word '{word}' should not be in vocabulary.\"\n",
        "\n",
        "        test_word = \"the\"\n",
        "        token_id = self.get_token_id(test_word)\n",
        "        assert self.get_token_str(token_id) == test_word.lower(), \"Round-trip token mapping failed.\"\n",
        "\n",
        "        print(\"Sanity check passed!\")\n",
        "\n",
        "vocab_builder = VocabularyBuilder(max_voc_size=20000)\n"
      ],
      "metadata": {
        "id": "CZJ4k7STz96H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only once!\n",
        "for paragraph in tqdm(training_set.splitlines()):\n",
        "  vocab_builder.build_vocabulary(paragraph)\n",
        "vocab_builder.create_vocabulary()"
      ],
      "metadata": {
        "id": "T1LhuLzfE2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b528bc88-62e5-4042-d91b-7ec6a13e4428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 294118/294118 [01:35<00:00, 3084.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save vocab so we don't have to rerun it\n",
        "counter= vocab_builder.token_counter\n",
        "with open(\"full_vocab\", 'w') as f:\n",
        "    for k,v in  counter.most_common():\n",
        "        f.write( \"{} {}\\n\".format(k,v) )"
      ],
      "metadata": {
        "id": "Z4cv1HQlQ0ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this using full_vocab from first run\n",
        "premade_counter = Counter()\n",
        "\n",
        "with open(\"/content/Intro-to-language-modeling/full_vocab\", 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.split(\" \")\n",
        "        if len(parts) == 2:\n",
        "            word, freq = parts[0], int(parts[1])\n",
        "            premade_counter[word] = freq\n",
        "vocab_builder.create_premade_vocabulary(premade_counter)\n"
      ],
      "metadata": {
        "id": "aIiqpkWcE8sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform sanity check\n",
        "vocab_builder.sanity_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1sB4W8Q0Qo9",
        "outputId": "21d19c0e-f1c7-46aa-9439-ff1132239ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingDataPreparer:\n",
        "    def __init__(self, vocab_builder, context_window_size):\n",
        "        self.vocab_builder = vocab_builder\n",
        "        self.N = context_window_size\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        \"\"\"Tokenizes and encodes a single string with special symbols.\n",
        "\n",
        "        Parameters:\n",
        "        - text (str): The input string to encode.\n",
        "\n",
        "        Returns:\n",
        "        - List[int]: A list of token IDs including BEGINNING and END tokens.\n",
        "        \"\"\"\n",
        "        # Tokenize the text\n",
        "        tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "        token_ids = [self.vocab_builder.get_token_id(token) for token in tokens]\n",
        "        modified_tokens = [0]*self.N # Add N BEGINNING\n",
        "        modified_tokens.extend(token_ids)\n",
        "        modified_tokens.append(1) # Add 1 END\n",
        "\n",
        "        return modified_tokens\n",
        "\n",
        "    def create_training_sequences(self, text):\n",
        "        \"\"\"\n",
        "        Creates training sequences from a single string by generating sequences of length N+1.\n",
        "\n",
        "        Parameters:\n",
        "        - text (str): The input string to create sequences from.\n",
        "\n",
        "        Returns:\n",
        "        - List[Tuple[List[int], int]]: A list of (context, target) pairs.\n",
        "        \"\"\"\n",
        "        training_sequences = []\n",
        "\n",
        "        encoded_text = self.encode_text(text)\n",
        "\n",
        "        for i in range(len(encoded_text) - self.N):\n",
        "            context = encoded_text[i : i + self.N]  # N tokens for context\n",
        "            target = encoded_text[i + self.N]       # Next token as the target\n",
        "            training_sequences.append((context, target))\n",
        "\n",
        "        return training_sequences\n"
      ],
      "metadata": {
        "id": "uXLrr6YeF0AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform manual inspection\n",
        "context_window_size = 3\n",
        "data_preparer = TrainingDataPreparer(vocab_builder, context_window_size)\n",
        "\n",
        "training_sequences = data_preparer.create_training_sequences(training_set[:100])\n",
        "\n",
        "print(\"Training sequences:\")\n",
        "for context, target in training_sequences[:10]:  # Show the first few sequences\n",
        "    print([vocab_builder.get_token_str(id) for id in context], \"->\", vocab_builder.get_token_str(target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A5cX52Y73i1",
        "outputId": "7ea4c4d3-0c79-4c40-8906-e684b8031148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sequences:\n",
            "['BEGINNING', 'BEGINNING', 'BEGINNING'] -> anatomy\n",
            "['BEGINNING', 'BEGINNING', 'anatomy'] -> anatomy\n",
            "['BEGINNING', 'anatomy', 'anatomy'] -> (\n",
            "['anatomy', 'anatomy', '('] -> greek\n",
            "['anatomy', '(', 'greek'] -> UNKNOWN\n",
            "['(', 'greek', 'UNKNOWN'] -> ,\n",
            "['greek', 'UNKNOWN', ','] -> “\n",
            "['UNKNOWN', ',', '“'] -> dissection\n",
            "[',', '“', 'dissection'] -> ”\n",
            "['“', 'dissection', '”'] -> )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a tensor dataset ##\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def TorchDataLoader(training_sequences, batch_size):\n",
        "  context_words = [item[0] for item in training_sequences]  # List of [context]\n",
        "  target_words = [item[1] for item in training_sequences]   # List of target words\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  context_tensor = torch.tensor(context_words, dtype=torch.long)  # Shape: (num_samples, 3)\n",
        "  target_tensor = torch.tensor(target_words, dtype=torch.long)    # Shape: (num_samples,)\n",
        "\n",
        "  # Create a TensorDataset\n",
        "  dataset = TensorDataset(context_tensor, target_tensor)\n",
        "\n",
        "  # Create a DataLoader for batching\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "DqKicZuza81v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preparer = TrainingDataPreparer(vocab_builder, 3)\n",
        "\n",
        "training_sequences = []\n",
        "split_training_set = training_set.splitlines()\n",
        "for paragraph in tqdm(split_training_set):\n",
        "  training_sequences.append(preparer.create_training_sequences(paragraph))\n",
        "flattened_training_sequences =  [\n",
        "    x\n",
        "    for xs in training_sequences\n",
        "    for x in xs\n",
        "]"
      ],
      "metadata": {
        "id": "dRXFfX7Zf4Hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e4df915-325c-480c-ec97-f8bd29829ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 294118/294118 [01:49<00:00, 2683.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preparer = TrainingDataPreparer(vocab_builder, 3)\n",
        "\n",
        "val_sequences = []\n",
        "split_val_set = val_set.splitlines()\n",
        "for paragraph in tqdm(split_val_set):\n",
        "  val_sequences.append(preparer.create_training_sequences(paragraph))\n",
        "flattened_val_sequences =  [\n",
        "    x\n",
        "    for xs in val_sequences\n",
        "    for x in xs\n",
        "]"
      ],
      "metadata": {
        "id": "2iMBAWK0VWxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8a2d81-2ae3-4f1b-cc36-88c6641b11bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35748/35748 [00:14<00:00, 2387.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = TorchDataLoader(flattened_training_sequences, 64)"
      ],
      "metadata": {
        "id": "5nNMuktjU1IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valloader = TorchDataLoader(flattened_val_sequences, 64)"
      ],
      "metadata": {
        "id": "9FpFFCWqVl2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3"
      ],
      "metadata": {
        "id": "6cxG6iHlclgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# EarlyStopping class remains the same\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, verbose=False, path='checkpoint.pth'):\n",
        "        self.patience = patience  # Number of epochs to wait for improvement\n",
        "        self.delta = delta  # Minimum change to qualify as an improvement\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.path = path  # Path to save the best model\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss < self.best_score - self.delta:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Save model when validation loss decreases.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "class SimpleANN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, layer_sizes,activation=nn.ReLU,last_layer_activation=nn.Softmax,dropout=0):\n",
        "\n",
        "        super(SimpleANN, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(layer_sizes)-2):\n",
        "          self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
        "          self.layers.append(nn.Dropout(dropout))\n",
        "          self.layers.append(activation())\n",
        "\n",
        "        self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
        "        if last_layer_activation is not None:\n",
        "         self.layers.append(nn.Dropout(dropout))\n",
        "         self.layers.append(last_layer_activation())\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embeddings(x)  # Get word embeddings for each word in the batch\n",
        "\n",
        "        # Flatten the input embeddings\n",
        "        x = embeddings.view(-1, np.prod(embeddings.shape[1:]))\n",
        "\n",
        "        x = x.float()\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Q2CkGhOV1JpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleANN(layer_sizes=[384, 1024, 20000], vocab_size=20000, embed_size=128)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "patience = 5\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "number_of_epochs = 20\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "    for batch_context, batch_target in tqdm(trainloader):\n",
        "        #FORWARD PASS:\n",
        "        X = batch_context\n",
        "        Y = batch_target\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        outputs = model(X)  # Model output for X\n",
        "        loss = criterion(outputs, Y) # Compute the loss between model output and Y\n",
        "\n",
        "        #BACKWARD PASS (updating the model parameters):\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()        # Compute gradients\n",
        "        optimizer.step()       # Update model parameters\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{number_of_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():  # No gradient computation for validation\n",
        "        for inputs, targets in valloader:\n",
        "            X = inputs\n",
        "            Y = targets\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, Y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(valloader)  # Average validation loss\n",
        "    print(f\"Epoch {epoch+1}/{number_of_epochs} - Perplexity: {np.exp(avg_val_loss):.6f}\")\n",
        "\n",
        "    # Call early stopping after each epoch\n",
        "    early_stopping(avg_val_loss, model)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "# Optionally, load the best model after training\n",
        "model.load_state_dict(torch.load('checkpoint.pth'))"
      ],
      "metadata": {
        "id": "7iUtwI8nbBO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "37c4fa34-2783-4da4-a263-9f900e3f44b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/192112 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "100%|██████████| 192112/192112 [31:14<00:00, 102.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 9.7607\n",
            "Epoch 1/20 - Perplexity: 17356.849107\n",
            "Validation loss decreased (inf --> 9.761742).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 192112/192112 [31:04<00:00, 103.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/20], Loss: 9.7607\n",
            "Epoch 2/20 - Perplexity: 17293.531248\n",
            "Validation loss decreased (9.761742 --> 9.758088).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 192112/192112 [31:01<00:00, 103.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/20], Loss: 9.7964\n",
            "Epoch 3/20 - Perplexity: 17215.652618\n",
            "Validation loss decreased (9.758088 --> 9.753574).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 192112/192112 [31:03<00:00, 103.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/20], Loss: 9.7250\n",
            "Epoch 4/20 - Perplexity: 17186.374537\n",
            "Validation loss decreased (9.753574 --> 9.751872).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 192112/192112 [31:02<00:00, 103.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 9.7250\n",
            "Epoch 5/20 - Perplexity: 17185.426177\n",
            "Validation loss decreased (9.751872 --> 9.751817).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 31542/192112 [05:06<25:59, 102.93it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f437c55753c0>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Model output for X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Compute the loss between model output and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "Hsm3CLoWgub5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are just some random sentences we thought might occur often based on the most common words\n",
        "test_sentences = [\"this is his\",\n",
        "                  \"and it was\",\n",
        "                  \"they were not\",\n",
        "                  \"it has been\"]\n",
        "\n",
        "encoded_sentences = []\n",
        "for sentence in test_sentences:\n",
        "  encoded_sentences.append([vocab_builder.get_token_id(sentence) for word in sentence.split(\" \")])\n",
        "\n",
        "device = next(model.parameters()).device\n",
        "encoded_sentences_tensor = torch.tensor(encoded_sentences).to(device)\n",
        "output = model(encoded_sentences_tensor).detach()\n",
        "\n",
        "# Predict\n",
        "predictions = torch.argmax(output, axis=1)\n",
        "\n",
        "for prediction in predictions:\n",
        "  print(vocab_builder.get_token_str(prediction))"
      ],
      "metadata": {
        "id": "HOp6TdEPgtmJ",
        "outputId": "0435e7d0-e3f0-4293-fb9b-ee592d9874b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNKNOWN\n",
            "UNKNOWN\n",
            "UNKNOWN\n",
            "UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = np.exp(avg_val_loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "id": "lb9-NZAhzYLG",
        "outputId": "fd42d61a-3c3f-41b9-86fa-b9ea5a92df92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17185.426176946003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbors(emb, voc, word, n_neighbors=5):\n",
        "\n",
        "    # Look up the embedding for the test word.\n",
        "    test_emb = emb.weight[voc.get_token_id(word)]\n",
        "\n",
        "    # We'll use a cosine similarity function to find the most similar words.\n",
        "    sim_func = nn.CosineSimilarity(dim=1)\n",
        "    cosine_scores = sim_func(test_emb, emb.weight)\n",
        "\n",
        "    # Find the positions of the highest cosine values.\n",
        "    near_nbr = cosine_scores.topk(n_neighbors+1)\n",
        "    topk_cos = near_nbr.values[1:]\n",
        "    topk_indices = near_nbr.indices[1:]\n",
        "    # NB: the first word in the top-k list is the query word itself!\n",
        "    # That's why we skip the first position in the code above.\n",
        "\n",
        "    # Finally, map word indices back to strings, and put the result in a list.\n",
        "    return [ (voc.get_token_str(ix.item()), cos.item()) for ix, cos in zip(topk_indices, topk_cos) ]\n",
        "\n",
        "print(nearest_neighbors(model.embeddings, vocab_builder, \"1984\"))\n",
        "print(nearest_neighbors(model.embeddings, vocab_builder, \"portugal\"))"
      ],
      "metadata": {
        "id": "Vm5IGathjhMx",
        "outputId": "de07275d-91ac-4997-b508-b09c774e29b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ironic', 0.37804847955703735), ('lasted', 0.3132971525192261), ('administrations', 0.3113548457622528), ('redesign', 0.3101631999015808), ('fuel', 0.2919778823852539)]\n",
            "[('protections', 0.35449904203414917), ('flood', 0.34666502475738525), ('emphasis', 0.3420579433441162), ('bnp', 0.32584938406944275), ('criticizing', 0.2990069091320038)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_embeddings_pca(emb, voc, words):\n",
        "    vectors = np.vstack([emb.weight[voc.get_token_id(w)].cpu().detach().numpy() for w in words])\n",
        "    vectors -= vectors.mean(axis=0)\n",
        "    twodim = TruncatedSVD(n_components=2).fit_transform(vectors)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, twodim):\n",
        "        plt.text(x+0.02, y, word)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_embeddings_pca(model.embeddings, vocab_builder, ['sweden', 'denmark', 'europe', 'africa', 'london', 'stockholm', 'large', 'small', 'great', 'black', '3', '7', '10', 'seven', 'three', 'ten', '1984', '2005', '2010'])\n"
      ],
      "metadata": {
        "id": "RpQwos6mj8di",
        "outputId": "a426c748-79ec-4192-b2a8-e275c6daf187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAAGVCAYAAABgjYFNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFxElEQVR4nO3de1xVVf7/8dcRUe4opoCAYl5QU9OyTIvENHXKJmWsGXVSv5lNpYVlZk1jWc6kY15rbLr9kqZETUQqrZwyUFIzNW+U4SXJQTGyvICm3D6/P8g9HsFGS66+n4/HeeTZa+291zrQebPXXntvl5kZIiIiF7lald0AERGRqkCBKCIiggJRREQEUCCKiIgACkQRERFAgSgiIgIoEEVERAAFooiICKBAFBERARSIIiIigAJRREQEUCCKiIgACkQRERFAgSgiIgIoEEVERAAFooiICKBAFBGpdr766iuuueYavLy86Nix41nrxcfHU69evQprV3XnMjOr7EaIiMi5+/3vf8/Bgwd57bXX8PPzo0GDBmXW+/HHH8nNzaVRo0YV3MLqqXZlN0BERM7P7t27ufnmm2natOlZ6xQUFODt7Y23t3cFtqx605CpiEgV88EHH3DddddRr149GjRoQL9+/di9ezcALpeLjRs38vTTT+NyuZg4cSKZmZm4XC4WLlxI9+7d8fLyYt68eWUOmb777rtcddVVeHl5cckllzBgwACn7I033qBz5874+/sTEhLC4MGDycnJqciuVyoFoohIFXPs2DEeeughNmzYwIoVK6hVqxYDBgyguLiY7OxsLrvsMsaOHUt2djYPP/yws96jjz5KXFwc27dvp0+fPqW2u2zZMgYMGMBNN93Epk2bWLFiBVdffbVTXlBQwKRJk9iyZQvJyclkZmYyfPjwiuhylaAhUxGRSlZUVERaWhrZ2dmEhobSv39/PDw8nPLXXnuNhg0b8uWXX9KuXTtq166Nn58fISEhABw8eBCAMWPGEBsbe9b9/O1vf+MPf/gDTz31lLPs8ssvd/595513Ov++9NJLee6557jqqqvIy8vDz8/vgvW3qlIgiohUoqSkJMbGxZGZleUsCwsOJrJFC/bv38/BgwcpLi4GYO/evbRr1+6s2+rcufPP7mvz5s2MHDnyrOUbN25k4sSJbNmyhUOHDrntt23btufTrWpJQ6YiIpUkKSmJgQMH0j4ri7VALrAWOPztt6xevZqhQ4eybt061q1bB0B+fv7Pbs/X1/dny39ugs2xY8fo06cPAQEBzJs3j/Xr17NkyZJz2m9NoUAUEakERUVFjI2Lo58ZycA1gB/QEjgGdAP+9dprtGrVikOHDl2QfXbo0IEVK1aUWfbVV1/x/fffM2XKFKKjo2nduvVFNaEGNGQqIlIp0tLSyMzKYj7uRyb1gQaAP7DmP/9h9uzZLFiw4ILs88knn6Rnz540b96cP/zhDxQWFvLee+8xfvx4mjRpQp06dXj++ee55557SE9PZ9KkSRdkv9WFjhBFRCpBdnY2AGeeEawFLAAyf3o/e/Zsnn322Quyz5iYGBYtWsQ777xDx44dueGGG/jss88AaNiwIfHx8SxatIi2bdsyZcoUpk2bdkH2W13oTjUiIpUgNTWVHj16sJaS4dIzraVk2DQlJYWYmJgKbdvFSoEoIlIJioqKaBEZSft9+0g2cxuuKwb6u1ykh4ezc88et0swpPxoyFREpBJ4eHgwffZsllISfqfPMu3vcrEUmDZrlsKwAikQRUQqSWxsLImJiWwLC6MbEEDJMGl6eDiJiYk/e5G9XHgaMhURqWRn3qkmOjpaR4aVQIEoIiKChkxFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBF5ALIz8+v7CaI/GoKRJGLUHFxMZMnT6ZZs2Z4e3tz+eWXk5iYCEB8fDz16tVzq5+cnIzL5XLeT5w4kY4dO/Lqq6/SrFkzvLy8ANi7dy+33norfn5+BAQEcPvtt/Ptt9+WWu+ll14iIiICHx8fbr/9do4cOeK2v1dffZU2bdrg5eVF69ateeGFF8rpkxD5r9qV3QARqXiTJ0/mzTff5MUXX6Rly5asWrWKP/7xjzRs2PCct7Fr1y4WL15MUlISHh4eFBcXO2G4cuVKCgsLGTVqFL///e9JTU11W++tt97i3Xff5ejRo4wYMYL77ruPefPmATBv3jyeeOIJ/vGPf9CpUyc2bdrEyJEj8fX1ZdiwYRf6oxD5LxORi8qJEyfMx8fH1qxZ47Z8xIgRNmjQIJs7d64FBga6lS1ZssRO/7p48sknzdPT03Jycpxl//73v83Dw8P27t3rLPviiy8MsM8++8xZz8PDw7Kyspw677//vtWqVcuys7PNzKx58+aWkJDgtv9JkyZZ165df13HRf4HHSGKXASKiopIS0sjOzubEydOcPz4cW688Ua3Ovn5+XTq1Omct9m0aVO3I8rt27cTERFBRESEs6xt27bUq1eP7du3c9VVVwHQpEkTwsLCnDpdu3aluLiYjIwM/P392b17NyNGjGDkyJFOncLCQgIDA8+73yLnQ4EoUsMlJSUxNi6OzKwst+Xjx49n0KBBbsvq1q1LSkoKZua2vKCgoNR2fX19L3hb8/LyAHjllVfo0qWLW5mHh8cF35/I6RSIIjVYUlISAwcOpJ8Z84F2wDqgN/DEE09w2WWXERsb67ZOw4YNyc3N5dixY07obd68+X/uq02bNvznP//hP//5j3OU+OWXX3L48GHatm3r1Nu7dy/79++ncePGAHz66afUqlWLqKgogoODady4MV9//TVDhgy5AJ+AyLlTIIrUUEVFRYyNi6OfGcn8d0p5T+BR4FngTyNH0q5dO/Ly8li9ejUBAQHccsst+Pj48Oc//5kHHniAdevWER8f/z/316tXL9q3b8+QIUOYNWsWhYWF3HfffXTv3p3OnTs79by8vBg2bBjTpk3j6NGjPPDAA9x+++2EhIQA8NRTT/HAAw8QGBhI3759OXnyJBs2bODQoUM89NBDF/ZDEjmNLrsQqaHS0tLIzMriz5T+H/2vwH3AwR9+4LLLLqNv374sW7aMZs2aERQUxJtvvsl7771H+/btmT9/PhMnTvyf+3O5XLz99tvUr1+f66+/nl69enHppZeycOFCt3otWrQgNjaWm266id69e9OhQwe3yyruuusuXn31VebOnUv79u3p3r078fHxNGvW7Nd+JCI/y2VnniwQkRph/vz5DB48mFzAr4zyXCAASEhIKHUusbxMnDiR5OTkcxqCFaloOkIUqaFCQ0MBSD9LefoZ9UQudgpEkRoqOjqayPBwnnG5KD6jrBiY7HLRLCKC6OjoymieSJWjIVORGsyZZQo8ZkY7So4MJ7tcLAUSExNLzTIVuVjpCFGkBouNjSUxMZFtYWF0o+ScYTcgPTxcYShyBh0hilwETr9TTWhoKNHR0brQXeQMCkQRERE0ZCoiIgIoEEVERAAFooiICKBAFBERARSIIiIigAJRREQEUCCKiIgACkQRkYtKTEwMY8aMqexmVEkKRBERERSIIiJyjsyMwsLCym5GuVEgiohcpN544w06d+6Mv78/ISEhDB48mJycHKc8NTUVl8vF+++/z5VXXkndunX55JNPyM3NZciQIfj6+hIaGsrMmTNLDcWePHmShx9+mLCwMHx9fenSpQupqakV38nzoEAUEblIFRQUMGnSJLZs2UJycjKZmZkMHz68VL1HH32UKVOmsH37djp06MBDDz3E6tWreeedd/jwww9JS0vj888/d1tn9OjRrF27lgULFrB161Zuu+02+vbty86dOyuod7+AiYjIRaN79+4WFxdXZtn69esNsNzcXDMzS0lJMcCSk5OdOkePHjVPT09btGiRs+zw4cPm4+PjbPebb74xDw8P27dvn9v2e/bsaY899tiF7dAFVLuyA1lERMrPmY/+stMecLRx40YmTpzIli1bOHToEMXFxQDs3buXtm3bOvU6d+7s/Pvrr7+moKCAq6++2lkWGBhIVFSU837btm0UFRXRqlUrt7acPHmSBg0aXPA+XigKRBGRGiopKYmxcXFkZmU5y+rWqYO/vz/Hjh2jT58+9OnTh3nz5tGwYUP27t1Lnz59yM/Pd9uOr6/vee03Ly8PDw8PNm7cWOq5m35+fr+8Q+VMgSgiUgMlJSUxcOBA+pkxH2gHpAP98vNZtmwZL7zwAt9//z1TpkwhIiICgA0bNvzP7V566aV4enqyfv16mjRpAsCRI0fYsWMH119/PQCdOnWiqKiInJwcoqOjy6mHF54CUUSkhikqKmJsXBz9zEjmv7Mnr6EkGPcC/5g1izp16vD8889zzz33kJ6ezqRJk/7ntv39/Rk2bBjjxo0jKCiIRo0a8eSTT1KrVi1cLhcArVq1YsiQIQwdOpTp06fTqVMnvvvuO1asWEGHDh24+eaby6fjv5JmmYqI1DBpaWlkZmXxZ8r+kr8K2Lt/P4888giLFi2ibdu2TJkyhWnTpp3T9mfMmEHXrl3p168fvXr14tprr6VNmzZ4eXk5debOncvQoUMZO3YsUVFR9O/f3+2osipy2elnWEVEpNqbP38+gwcPJhco64xdLhAAJCQkMGjQoF+9v2PHjhEWFsb06dMZMWLEr95eZdGQqYhIDRMaGgqUnDO8pozy9DPqna9Nmzbx1VdfcfXVV3PkyBGefvppAG699dZftL2qQkOmIiI1THR0NJHh4TzjclF8RlkxMNnlollExK+a8DJt2jQuv/xyevXqxbFjx0hLS+OSSy75Ve2ubBoyFRGpgZxZpsBjZs4s08kuF0uBxMREYmNjK7eRVYyOEEVEaqDY2FgSExPZFhZGN0rOGXYD0sPDFYZnoSNEEZEa7Mw71URHR5e6WF5KKBBFRETQkKmIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBSRi1BkZCQul6vUa9SoUZXdNKlEtSu7ASIiFW39+vUUFRU579PT07nxxhu57bbbKrFVUtl0hCgiZXK5XCQnJ5+1PDIyklmzZv2qfQwfPpz+/fv/qm2cLiYmhjFjxvzPeg0bNiQkJMR5LV26lObNm9O9e/cL1hapfhSIItXchQ6Vi01+fj5vvvkmd955Jy6Xq7KbI5VIgSgiF7Xk5GQOHz7M8OHDK7spUskUiCLVRGJiIu3bt8fb25sGDRrQq1cvxo0bx+uvv87bb7/tTAxJTU0FYNu2bdxwww1O/bvvvpu8vDy3bb722mtcdtll1K1bl9DQUEaPHn3W/T/55JOEhoaydetWZ9nx48e588478ff3p0mTJrz88stu7QwMDCQoKAgvLy9cLhdDhw4lLy+PH374gVq1arFy5UpnW3/9618JDAzk/vvvZ8yYMQQEBFC3bl3q1q1Lo0aNaN68OX5+frRo0YL333+fY8eOMXToUPz8/AgNDWX69Oml2nzy5EkefvhhwsLC8PX1pU2bNkyYMIHU1FSKioqIj49nyJAhdO7cmZ49e+Ln50ffvn3Jzs7+lT8tqZZMRKq8/fv3W+3atW3GjBm2Z88e27p1q82ZM8dyc3Pt9ttvt759+1p2drZlZ2fbyZMnLS8vz0JDQy02Nta2bdtmK1assGbNmtmwYcOcbb7wwgvm5eVls2bNsoyMDPvss89s5syZTjlgS5YsseLiYhs9erRFRkbazp07nfKmTZtaUFCQzZkzx3bu3GmTJ0+2WrVqmYeHh82YMcO++OILa9iwoXXs2NE+/fRTCwgIsEaNGtmwYcMsOTnZLrnkEvPy8rJbb73VzMx69eplTZo0MX9/f3v88cetfv36dv3115uHh4dde+211qZNG+vSpYvde++91qBBA7vrrrusSZMm9tFHH9nWrVutX79+5u/vb3FxcU4b77rrLuvWrZtNmjTJwkJCDHBekeHhdscddxhgHTp0sPXr19vGjRutTZs2Nnjw4HL+iUpVpEAUqQY2btxogGVmZpYqGzZsmBMqp7z88stWv359y8vLc5YtW7bMatWqZQcOHDAzs8aNG9vjjz9+1n0CtmjRIhs8eLC1adPGsrKy3MqbNm1qf/zjH533xcXFFhQU5LTzzDbExsbazTffbLVq1bKRI0fauHHjrE6dOtazZ0/Lz883Hx8f69Chg1133XU2adIk6927txUWFpqvr6/dcccd9p///McA++STTwyw2rVr21tvveXs//vvvzdvb28nEL/55hvz8PCwV155xVwul90CthYsBmwo2C0ulxOOX331lbOdOXPmWHBw8P/4iUhNpMsuRKqooqIi0tLSyM7OplGjRtxwww20b9+ePn360Lt3bwYOHEj9+vXLXHf79u1cfvnl+Pr6OsuuvfZaiouLycjIwOVysX//fnr27PmzbXjwwQepW7cun376KZdcckmp8nbt2pGamkp2djahoaGEhYURGBhI+/btCQkJoWHDhuTn5+Pr60v37t355z//SXFxMampqTz33HMsWLCAgwcPsn79egoKCpx1t2zZQkpKCoGBgRw/fpwFCxaQlJQEwJEjRwAoLCykS5cuTluCgoKIiopy3m/bto2ioiLuvvtuapnxMfAxcBKIBZLM8AEKgBYtWjjrhYaGkpOT87Ofi9RMOocoUgUlJSXRIjKSHj16MHjwYHr16sXujAweffRR2rZty/PPP09UVBR79uz5Rdv39vY+p3o33ngj+/btY/ny5aXKjh8/zt8nT3ba2KNHD7766is6d+7M+++/T1BQEPv27XPaGRMTw1dffQVAZmYm1113HSEhIRw8eJCVK1fSuXNnatWqhaenJ3l5edxyyy1s3ryZxo0bM27cODZv3szOnTvP+dKIvLw8atWqhZkxH9j802s7MJuScCz4qW5aWpqznsvlwszOaR9SsygQRaqYpKQkBg4cSPusLNYCucBaoMP+/fzlL3/h8ssvZ9OmTdSpU4clS5ZQp04dt4vMAdq0acOWLVs4duyYs2z16tXUqlWLqKgo/P39iYyMZMWKFT/blt/+9rckJCRw1113sWDBArc2fvfddzQ+csStjd4FBSxatIhvv/2WESNGUKdOHWrXrs2SJUto3749fn5+uFwu59+nAjE1NZWYmBhn+1dccQVffPEFkZGR1K5dm4YNG9KiRQtatGjhHPV6eHiwbt06Z51Dhw6xY8cO532nTp0oLi4G4DdAi9NeIUBv4J8/1dUkGgEFokiVUlRUxNi4OPqZkQxcA/gBLqCLGdeZMWb0aBITE/nuu+9o06YNkZGRbN26lYyMDA4ePEhBQQFDhgzBy8uLYcOGkZ6eTkpKCvfffz933HEHwcHBAEycOJHp06fz3HPPsXPnTj7//HOef/75Um0aMGAAb7zxBv/3f/9HYmKi00ZvYMRpbbwGCAYaAPffdx/XXnstAAcOHMDb25vU1FQnoG688UYA6tevT3FxMStWrHA78hs1ahQ//PADgwYNIj8/n4MHD7J8+XL+7//+zwn/U7NsP/74Y9LT0xk+fDi1av33K61Vq1b06tULgH8Ae4DPgMnAsp/qZP3039DQ0F/8M5MapLJPYorIf6WkpBg/Tf6w015fgvUBq/fTJJCIiAh7/vnnzcwsJyfHbrzxRvPz8zPAUlJSzMxs69at1qNHD/Py8rKgoCAbOXKk5ebmuu3vxRdftKioKPP09LTQ0FC7//77nTJ+mmV6ysKFC83Ly8ueeuopAywEbOYZ7YwCC/upjZ6enta0aVNr2bKl04ZrrrnGAHv//ffNrGRCUEhIiNWuXdtyc3Ote/fuzqSYHTt22IABA8zlcpmnp6e1bt3axowZY8XFxQZYQkKC/fGPfzQfHx8LDg62qVOnuq1vZvbjjz9aoL+/eYN5goWCDQDbClYE1hGslstlhYWFzjpLliwxfTVenPRTF6lCEhISDLDcM4Lm1OvoT2GTkJCgNp6jxYsXl8wydblszU/tW/PTLFOXy2WLFy+u7CZKFaEhU5Eq5NTQXfpZytPPqFcZqkMbTxcbG0tiYiLbwsLoBgQA3YD08HASExOJjY2t5BZKVeEy03QqkaqiqKiIFpGRtN+3j2Qzt5P8xUB/l4v08HB27tmDh4eH2ngeTr+MJTQ0lOjo6CrVPql8OkIUqUI8PDyYPns2SykJltNncPZ3uVgKTJs1q1K/yKtDG8vi4eFBTEwMgwYNIiYmpsq1TyqfAlGkiqkOQ3zVoY0i50tDpiJVVHUY4qsObRQ5VwpEERERNGR60Zg4cSIdO3Z03uuhsiIi7hSIIiIiKBBFREQABWKlKevp58eOHXOGMp955hmCg4OpV68eTz/9NIWFhYwbN46goCDCw8OZO3eu2/bGjx9Pq1at8PHx4dJLL2XChAkUFBScZe8iInImPQ+xEmRnZzNo0CCmTp3KgAEDyM3NJS0tzXnkzMcff0x4eDirVq1i9erVjBgxgjVr1nD99dezbt06Fi5cyJ/+9CduvPFGwsPDAfD39yc+Pp7GjRuzbds2Ro4cib+/P4888khldlVEpNrQLNNK8Pnnn3PllVeSmZlJ06ZN3cqGDx9OamoqX3/9tXPn/tatW9OoUSNWrVoFlEx1DwwM5NVXX+UPf/hDmfuYNm0aCxYsYMOGDUDJpJrk5GQ2b97s7Ofw4cMkJyeXTydFRKoZHSFWkPN5+vlll13m9hib4OBg2rVr57z38PCgQYMGbk/1XrhwIc899xy7d+8mLy+PwsJCAgICKq6DIiLVnM4hVoDzffq5p6en2/oul6vMZaeeLbd27VqGDBnCTTfdxNKlS9m0aROPP/44+fn5FdNBEZEaQIFYzs736ee/xJo1a2jatCmPP/44nTt3pmXLlnzzzTcXshsiIjWehkzL0ZlPPz/118epp58fBsaMHk1BQYHz9POtW7ee935atmzJ3r17WbBgAVdddRXLli37xeEqInKx0hFiOUpLSyMzK4s/4/5BBwBpwDbgP9nZjBs3junTp/Ob3/zmF+3nt7/9LQ8++CCjR4+mY8eOrFmzhgkTJvz6Dohc5FJTU3G5XBw+fLiymyIVQLNMy9H8+fMZPHgwuYBfGeW5lIRjQkICgwYNqtjGidRg+fn51KlT51dvJzU1lR49enDo0CHq1av36xsmVZqOEMtRdXuyuEhVlZuby5AhQ/D19SU0NJSZM2cSExPDmDFjAIiMjGTSpEkMHTqUgIAA7r77bgA++eQToqOj8fb2JiIiggceeIBjx445233jjTfo3Lkz/v7+hISEMHjwYGf2dmZmJj169ACgfv36uFwuhg8fXqH9loqlQCxH0dHRRIaH84zLRfEZZcXAZJeLZhERREdHV0bzRKqNhx56iNWrV/POO+/w4YcfkpaWxueff+5WZ9q0ac4ktQkTJrB792769u3L7373O7Zu3crChQv55JNPGD16tLNOQUEBkyZNYsuWLSQnJ5OZmemEXkREBIsXLwYgIyOD7OxsZs+eXWF9lkpgUq4WL15sLpfLbnG5bA3YUbA1YLe4XOZyuWzx4sWV3cQKt3LlSuvXr5+FhoYaYEuWLHErP3DggA0bNsxCQ0PN29vb+vTpYzt27HCrk52dbX/84x8tODjYfHx8rFOnTpaYmFjm/k6cOGGXX365AbZp06Zy6pWUl6NHj5qnp6ctWrTIWXb48GHz8fGxuLg4MzNr2rSp9e/f3229ESNG2N133+22LC0tzWrVqmU//vhjmftav369AZabm2tmZikpKQbYoUOHLlyHpMrSEWI505PFSzt27BiXX345c+bMKVVmZvTv35+vv/6at99+m02bNtG0aVPnXq+nDB06lIyMDN555x22bdtGbGwst99+O5s2bSq1zUceeYTGjRuXa5/kwioqKiI1NZX58+ezcOFCCgoKuPrqq53ywMBAoqKi3Nbp3Lmz2/stW7YQHx+Pn5+f8+rTpw/FxcXONb8bN27klltuoUmTJvj7+9O9e3cA9u7de0H7c7Z7FwO8+uqrtGnTBi8vL1q3bs0LL7zgrNetWzfGjx/vtq3vvvsOT09P585VJ0+e5OGHHyYsLAxfX1+6dOlCamqqUz8+Pp569eqxfPly2rRpg5+fH3379iU7O/uC9rFGqOxEvlgUFhZaSkqKJSQkWEpKihUWFlZ2k6oEzjhCzMjIMMDS09OdZUVFRdawYUN75ZVXnGW+vr72r3/9y21bQUFBbnXMzN577z1r3bq1ffHFFzpCrCYWL15skeHhBri9XnzxRbd6nTp1cjtCnDlzplt569at7f7777edO3eWep08edLy8vKsQYMGNnjwYFu1apVt377dli9f7vZ7ciGOEPfv32+1a9e2GTNm2J49e2zr1q02Z84cy83NtTfffNNCQ0Nt8eLF9vXXX9vixYstKCjI4uPjzczsH//4hzVp0sSKi4ud7T3//PNuy+666y7r1q2brVq1ynbt2mXPPvus1a1b1xlVmTt3rnl6elqvXr1s/fr1tnHjRmvTpo0NHjz4F/epplIgSqU6MxC3bt1qgO3atcutXnh4uA0bNsx5f+ONN9rNN99s33//vRUVFdn8+fPNx8fHdu7c6dQ5cOCAhYWF2fr1623Pnj0KxGrAOcUAthYsF+wjMNdPoXjqFMPhw4fN19f3ZwNx8ODB1rNnz7Pua8OGDQbY3r17nWVvvPGG2+/J6tWrDbCDBw/+4j5t3LjRAMvMzCxV1rx5c0tISHBbNmnSJOvatauZmeXk5Fjt2rVt1apVTnnXrl1t/PjxZmb2zTffmIeHh+3bt89tGz179rTHHnvMzEoC8cz/p+bMmWPBwcG/uE81lQJRKtWZgZifn29NmjSx2267zX744Qc7efKkTZkyxQDr3bu3U+/QoUPWu3dvA6x27doWEBBgy5cvd8qLi4utb9++NmnSJDMzBWI1UFhYaJHh4XYLWBGYnfYaAeYDFtKwoW3ZssV+97vfmb+/v40ZM8bMyg7ELVu2mLe3t40aNco2bdpkO3bssOTkZBs1apSZlYRNnTp1bNy4cbZ79257++23rVWrVm6/J1lZWeZyuSw+Pt5ycnKcc4v/qx+njwadPHnSevbsaf7+/jZw4EB7+eWX7YcffrC8vDwDzNvb23x9fZ1X3bp1rVGjRs72brrpJvvTn/5kZmZff/21AbZ161YzM1u6dKkBbuv7+vpa7dq17fbbbzezkkD08fFxa2NSUpK5XK7z/yHVcDqHKOXu9PNBqampFBUVnbWup6cnSUlJ7Nixg6CgIHx8fEhJSeE3v/mN2w3PJ0yYwOHDh/noo4/YsGEDDz30ELfffjvbtm0D4Pnnnyc3N5fHHnus3PsnF8bZbmQBMBO4Djjw3Xf06NGDa6+91jnvdjYdOnRg5cqV7Nixg+joaDp16sQTTzzhnE9u2LAh8fHxLFq0iLZt2zJlyhSmTZvmto2wsDCeeuopHn30UYKDg91mqJblzPsW9+jRg6jmzbn33nt5//333e5dnJ5ecuHVK6+8wubNm51Xeno6n376qbPNIUOGkJiYSEFBAQkJCbRv35727dsDkJeXh4eHBxs3bnTbxvbt291mxJZ1L2TTJeilVXYiS81W1vmgyPBwZ+iLMmaZnnL48GHLyckxM7Orr77a7rvvPjMz27VrV6nzjGYlw0Sn/pK+9dZbrVatWubh4eG8APPw8LChQ4eWU2/l10hISCiZ4XnG0eGp19Gffn8SEhIsLy/PAgMD7dVXX63sZjvKGu5dW8aM8sLCQgsLC7Pp06db48aN7emnn/7Z7ebl5Zmvr6+988471rZtW5syZYpTduqc++lDqmeaO3euBQYGui1bsmSJ6eu/NN3LVMrNqRub9zNjPtCOkpsRPLNvHwMHDiQxMfFn1w8MDARg586dbNiwgUmTJgFw/PhxALcjRih5LNapJ4A899xz/PWvf3XK9u/fT58+fVi4cCFdunS5MB2UC+r0G1lcc0bZJuCdn/596iJ9gFtvvbWimvezznbf4muAx8zYCdx/33106tSJDRs2OPcufuqpp3jggQcIDAykb9++nDx5kg0bNnDo0CEeeughAHx9fenfvz8TJkxg+/btbne1atWqFUOGDGHo0KFMnz6dTp068d1337FixQo6dOjAzTffXMGfRDVX2YksNdPPnQ86AnY9WOPgYANsxowZtmnTJvvmm2/MzOytt96ylJQU2717tyUnJ1vTpk0tNjbW2XZ+fr61aNHCoqOjbd26dbZr1y6bNm2auVwuW7ZsWZnt0TnEqs/5nXG5Sv3ObAALBHO5XFa/fn3r1auXcx6tKjg1G3VtGUe2X4J1+eno1tPT01q1amXPP/+8s+68efOsY8eOVqdOHatfv75df/31lpSU5Lb99957zwC7/vrrS+07Pz/fnnjiCYuMjDRPT08LDQ21AQMGOJ+PjhDPnT4RKRc/9wWRcsZ0+lOvU7NIZ8+ebeHh4ebp6WlNmjSxv/zlL3by5Em37e/YscNiY2OtUaNG5uPjYx06dCh1GcbpFIjVQ3W9kcX5DPdK1aVAlHKhLwj5pco679wsIqLKhqHZz/8BaD+FOmApKSmV3VT5GXrahZSLU08JWEvp80FQ8pDkbkBKSgoxMTEV2jap+oqKikhLSyM7O5vQ0FCio6Px8PCo7GadVVFRES0iI2m/bx/JZm6zZIuB/i4X6eHh7Nyzp0r342KnQJRyoS8Iudg4k8gomUhzahLZZJeLpXDR3qqxOtF1iFIuPDw8mD57NkspCb+1lDz/ce1P75cC02bNUhhKjaH7Fld/OkKUcpWUlMTYuDgys7KcZc0iIpg2a5a+IKRGqm7DvfJfCkQpd1X1C2LVqlU8++yzbNy4kezsbJYsWUL//v2dcjPjySef5JVXXuHw4cNce+21/POf/6Rly5aV12gRKTcaMpVy5+HhQUxMDIMGDSImJqZKhCH8/GOoAKZOncpzzz3Hiy++yLp16/D19aVPnz6cOHGiglsqIhVBR4gilNzb8fQjRDOjcePGjB07locffhiAI0eOEBwcTHx8PH/4wx8qsbUiUh50hChShj179nDgwAF69erlLAsMDKRLly6sXbu2ElsmIuVFgShShgMHDgAQHBzstjw4ONgpE5GaRTf3lotGVZ3cIyJVg44Q5aJQ1nPqWkRGkpSUVGb9kJAQAL799lu35d9++61TJiI1iwJRarxTdxBpn5XldoOA9j89hqqsUGzWrBkhISGsWLHCWXb06FHWrVtH165dK6ztIlJxNMtUajTnFnJZWW7PqQM4CtwC7AoOZv+33zJjxgx69OhBUFAQTZo04e9//ztTpkzh9ddfp1mzZkyYMIGtW7fy5Zdf/uyT2kWkelIgSo32czcZTwV6lLHOsGHDiI+Pdy7Mf/nllzl8+DDXXXcdL7zwAq1atSr3dotIxVMgSo02f/58Bg8eTC7gV0Z5LiX3nExISHB7ErmIXHx0DlFqtNDQUKDkqQNlST+jnohcvBSIUqNFR0cTGR7OMy4XxWeUFVPyaJ5mERFER0dXRvOkEkyePJmrrroKf39/GjVqRP/+/cnIyHCrc+LECUaNGkWDBg3w8/Pjd7/7XakZxw888ABXXnkldevWpWPHjmXua+vWrURHR+Pl5UVERARTp04tr27JBaBAlBpNj6GSM61cuZJRo0bx6aef8uGHH1JQUEDv3r05duyYU+fBBx/k3XffZdGiRaxcuZL9+/eX+XSWO++8k9///vdl7ufo0aP07t2bpk2bsnHjRp599lkmTpzIyy+/XG59k1/JRC4CixcvtsjwcAOcV7OICFu8eHFlN00qWU5OjgG2cuVKMzM7fPiweXp62qJFi5w627dvN8DWrl1bav0nn3zSLr/88lLLX3jhBatfv76dPHnSWTZ+/HiLioq68J2QC0JHiHJRiI2NZVdmJikpKSQkJJCSksLOPXv0TEbhyJEjAAQFBQGwceNGCgoK3O5j27p1a5o0aXJe97Fdu3Yt119/PXXq1HGW9enTh4yMDA4dOnSBWi8Xkm7dJheNU4+hEjmluLiYMWPGcO2119KuXTug5D62derUoV69em51z/c+tgcOHKBZs2altnGqrH79+r+u8XLBKRBFpMY7231sR40aRXp6Op988kllN1GqAAWiiNRoSUlJjI2LIzMry1kWGR5O63btSE9PZ9WqVYSHhztlISEh5Ofnc/jwYbejxPO9j21ISEiZ98I9VSZVj84hikiNVdZ9bNcAZGXxwQcfMH78+FLDmldeeSWenp5u97HNyMhg796953Uf265du7Jq1SoKCgqcZR9++CFRUVEaLq2idKcaEamRznYf2/uABKAtkNW4MWs/+wwPDw8CAwPx9vYG4N577+W9994jPj6egIAA7r//fgDWrFnjbH/Xrl3k5eXx4osvkpKSwsKFCwFo27YtderU4ciRI0RFRdG7d2/Gjx9Peno6d955JzNnzuTuu++uqI9BzkdlT3MVESkPKSkpJZdKgNlpL87ymjt3rrPujz/+aPfdd5/Vr1/ffHx8bMCAAZadne22/e7du5e5nT179jh1tmzZYtddd53VrVvXwsLCbMqUKRXUe/kldIQoIjWS7mMr50vnEEWkRtJ9bOV86QhRRGok5xzivn0km7n99V9Mya370sPD2blnj27dJ4COEEWkhtJ9bOV8KRBFpMaKjY0lMTGRbWFhdKPknGE3ID08nMTERN26T9xoyFREaryz3alG5HQKRBERETRkKiIiAigQRUREAAWiiFRzMTExjBkzprKbITWAAlFERAQFoohUY8OHD2flypXMnj0bl8uFy+UiMzOT9PR0fvOb3+Dn50dwcDB33HEHBw8edNaLiYnhgQce4JFHHiEoKIiQkBAmTpxYeR2RKkGBKCLV1uzZs+natSsjR44kOzub7Oxs/P39ueGGG+jUqRMbNmzggw8+4Ntvv+X22293W/f111/H19eXdevWMXXqVJ5++mk+/PDDSuqJVAW67EJEqrWYmBg6duzIrFmzAPjrX/9KWloay5cvd+pkZWURERFBRkYGrVq1IiYmxrk28ZSrr76aG264gSlTplR0F6SKqF3ZDRAROR9nXmR/5t/0W7ZsISUlBT+/0s+42L17N61atQKgQ4cObmWhoaHk5OSUX8OlyqsygZiamkqPHj04dOgQ9erVq+zmiEgVlJSUxNi4ODKzspxldevUwd/f33mfl5fHLbfcwt///vdS65/+ZAtPT0+3MpfLRXFxcTm0WqqLSjuHqKnSNd//+hlHRkY6w1wVsT+p3pKSkhg4cCDts7LcbtTtn5/PsmXLSEpKAuCKK67giy++IDIykhYtWri9fH19K7MLUsVV60k1+fn5ld0EEakARUVFjI2Lo58ZycA1lDz09xqgP1APiBs9mm+//ZZRo0bxww8/MGjQINavX8/u3btZvnw5//d//0dRUVGl9UGqvkoJxLNNlQbYuHEjnTt3xsfHh27dupGRkeGsN3HiRDp27Mirr75Ks2bN8PLyAuDw4cPcddddNGzYkICAAG644Qa2bNnits+3336bK664Ai8vLy699FKeeuopCgsLK6zPIvLLpaWlkZmVxZ8p/aU1DggDsrKzCQkJIT8/n9WrV1NUVETv3r1p3749Y8aMoV69etSqVa2PAaScVcpvR1lTpSMiIgB4/PHHmT59Ohs2bKB27drceeedbuvu2rWLxYsXk5SUxObNmwG47bbbyMnJ4f3332fjxo1cccUV9OzZkx9++AEo+Z9p6NChxMXF8eWXX/LSSy8RHx/P3/72twrt98WosLCQ0aNHExgYyCWXXMKECRNKTYI4ZcaMGbRv3x5fX18iIiK47777yMvLc6uzevVqYmJi8PHxoX79+vTp04dDhw6Vub1ly5YRGBjIvHnzLni/pGJlZ2cD0K6MslaUDJ0CJCQkEBkZScuWLUlKSuLQoUMcP36c7du3M3PmTFwuF1AyZ+HM4frk5GTi4+PLqwtSHVgl6d69u8XFxTnvU1JSDLCPPvrIWbZs2TID7McffzQzsyeffNI8PT0tJyfHqZOWlmYBAQF24sQJt+03b97cXnrpJTMz69mzpz3zzDNu5W+88YaFhoZe6G7Jabp3725+fn4WFxdnX331lb355pvm4+NjL7/8spmZNW3a1GbOnOnUnzlzpn388ce2Z88eW7FihUVFRdm9997rlG/atMnq1q1r9957r23evNnS09Pt+eeft++++87Z36nfqXnz5pm/v7+9++67FdZfKT+nvh/WglkZrzVggKWkpFR2U6Uaq7BZpv9rqvQpp0+FPjUjLCcnhyZNmgDQtGlTGjZs6NTZsmULeXl5NGjQwG07P/74I7t373bqrF692u2IsKioiBMnTnD8+HF8fHwuTCellIiICOcv86ioKLZt28bMmTMZOXJkqbqnT4iJjIzkr3/9K/fccw8vvPACAFOnTqVz587Oe4DLLrus1HbmzJnD448/zrvvvkv37t0vfKekwkVHRxMZHs4z+/aRbOY2tFUMTHa5aBYeTnR0dGU1UWqACgnEc5kqfcrpU6FPDW+cPhX6zFlieXl5hIaGkpqaWmpbpy7fyMvL46mnnirz6dinzkPKr1fWHz3XXHON83ME6Nq1K9OnTy9zcsNHH33E5MmT+eqrrzh69CiFhYVuf7Rs3ryZ22677WfbkJiYSE5ODqtXr+aqq6664H2UyuHh4cH02bMZOHAg/V0uHjOjHZBOSRguBRJnzdJDf+VXKfdAPDVVup8Z88H5Jb7ltKnSZQXVubriiis4cOAAtWvXJjIy8qx1MjIyaNGixS/ej/y8s/3RU7v2uf2KZWZm0q9fP+69917+9re/ERQUxCeffMKIESPIz8/Hx8cHb2/v/7mdTp068fnnn/Paa6/RuXNntzCW6i02NpbExETGxsXR7bTfs2bh4STOmvWrvkdEoJwn1ZzPVOlfekFsr1696Nq1K/379+ff//43mZmZrFmzhscff5wNGzYA8MQTT/Cvf/2Lp556ii+++ILt27ezYMEC/vKXv1yAXsrZrg/zy8/n448/dq4PA/j0009p2bJlqb/kN27cSHFxMdOnT+eaa66hVatW7N+/361Ohw4dWLFixc+2pXnz5qSkpPD2229z//33X6AeSlURGxvLrsxMUlJSSEhIICUlhZ179igM5cIozxOUP3ciPAPssp9OhAM2d+5cA+zQoUPO+ps2bTLA9uzZY2Ylk2ouv/zyUvs5evSo3X///da4cWPz9PS0iIgIGzJkiO3du9ep88EHH1i3bt3M29vbAgIC7Oqrr3Ymd8gvV1hYaJHh4XYLWNEZP+PuYB5gAX5+9sUXX1hCQoL5+vraiy++aGbuk2o2b95sgM2aNct2795t//rXvywsLMztdyIjI8Pq1Klj9957r23ZssW2b99uL7zwQpmTar766isLCQlxm7glIvJzyjUQExISDLDcs8wMO/pTGCYkJJRnM6Qc/dwfPd3BYn/6Gfv6+lr9+vXtz3/+sxUXF5tZ6VmmM2bMsNDQUPP29rY+ffrYv/71r1J/JKWmplq3bt2sbt26Vq9ePevTp49TfubM5S+//NIaNWpkDz30UAV8EiJS3ZXr0y5O3Z90LSXDpGdaC3QDUlJSiImJKa9mSDmaP38+gwcPJpeS4fAz5QIBlFwfNmjQoIptnIjIeSjXc4jOVGmXizPPEDpTpSMiNFW6Gjt1aUz6WcrTz6gnIlJVlWsgnpoqvRTo73K5Tbjo/9NU6WmaKl2t6Y8eEakpyv3WbaemSm8LC6MbJcNn3YD08HASExM1O6ya0x89IlJTlOs5xNOdedF2dHS0viRrkLKuQ2wWEcE0XR8mItVEhQWi1Hz6o0dEqjMFooiICNX8AcEiIiIXigJRREQEBaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQRESAmJoYxY8ZUdjN+sQvRfgWiiIgICkQREanG8vPzL9i2FIgiIheZY8eOMXToUPz8/AgNDWX69Olu5SdPnuThhx8mLCwMX19funTpQmpqqlMeHx9PvXr1WL58OW3atMHPz4++ffuSnZ3t1Bk+fDj9+/fnmWeeITg4mHr16vH0009TWFjIuHHjCAoKIjw8nLlz57rte/z48bRq1QofHx8uvfRSJkyYQEFBgVM+ceJEOnbsyKuvvkqzZs3w8vIqs4/Lli0jMDCQefPmnfPnokAUEbnIjBs3jpUrV/L222/z73//m9TUVD7//HOnfPTo0axdu5YFCxawdetWbrvtNvr27cvOnTudOsePH2fatGm88cYbrFq1ir179/Lwww+77efjjz9m//79rFq1ihkzZvDkk0/Sr18/6tevz7p167jnnnv405/+RFZWlrOOv78/8fHxfPnll8yePZtXXnmFmTNnum13165dLF68mKSkJDZv3lyqfwkJCQwaNIh58+YxZMiQc/9gTERELhq5ublWp04de+utt5xl33//vXl7e1tcXJx988035uHhYfv27XNbr2fPnvbYY4+ZmdncuXMNsF27djnlc+bMseDgYOf9sGHDrGnTplZUVOQsi4qKsujoaOd9YWGh+fr62vz588/a3meffdauvPJK5/2TTz5pnp6elpOT41ave/fuFhcXZ//4xz8sMDDQUlNTz/UjcdQ+9+gUEZHqqKioiLS0NLKzszl27Bj5+fl06dLFKQ8KCiIqKgqAbdu2UVRURKtWrdy2cfLkSRo0aOC89/HxoXnz5s770NBQcnJy3Na57LLLqFXrvwORwcHBtGvXznnv4eFBgwYN3NZbuHAhzz33HLt37yYvL4/CwkICAgLcttu0aVMaNmxYqp+JiYnk5OSwevVqrrrqqnP6bE6nQBQRqcGSkpIYGxdH5mnDkgDvv/8+f/rTn0rVz8vLw8PDg40bN+Lh4eFW5ufn5/zb09PTrczlcmFmbsvKqlPWsuLiYgDWrl3LkCFDeOqpp+jTpw+BgYEsWLCg1DlOX1/fMvvaqVMnPv/8c1577TU6d+6My+Uqs97ZKBBFRGqopKQkBg4cSD8z5gPtgM+AXsA999xDw4YNiY2N5dChQ+zYsYPu3bvTqVMnioqKyMnJITo6ukLbu2bNGpo2bcrjjz/uLPvmm2/Oef3mzZszffp0YmJi8PDw4B//+Md57V+TakREaqCioiLGxsXRz4xk4BrAD7gBuBvwBkbdcw9btmxh+PDhztBmq1atGDJkCEOHDiUpKYk9e/bw2WefMXnyZJYtW1aubW7ZsiV79+5lwYIF7N69m+eee44lS5ac1zZatWpFSkoKixcvPu8L9RWIIiI1UFpaGplZWfyZ0l/004DrgQPffUePHj247rrruPLKK53yuXPnMnToUMaOHUtUVBT9+/dn/fr1NGnSpFzb/Nvf/pYHH3yQ0aNH07FjR9asWcOECRPOeztRUVF8/PHHzJ8/n7Fjx57zei47c9BXRESqvfnz5zN48GByKTkyPFMuEMB/L1EQHSGKiNRIoaGhAKSfpTz9jHqiI0QRkRqpqKiIFpGRtN+3j2Qzt6OfYqC/y0V6eDg79+wpNZv0YqUjRBGRGsjDw4Pps2ezlJLwW0vJMOnan94vBabNmqUwPI0CUUSkhoqNjSUxMZFtYWF0o+ScYTcgPTycxMREYmNjK7mFVYuGTEVEarjT71QTGhpKdHS0jgzLoEAUERFBQ6YiIiKAAlFERARQIIqIVIrJkydz1VVX4e/vT6NGjejfvz8ZGRludU6cOMGoUaNo0KABfn5+/O53v+Pbb791q7N3715uvvlmfHx8aNSoEePGjaOwsNApT01NxeVylXodOHCgQvpZnSgQRUQqwcqVKxk1ahSffvopH374IQUFBfTu3Ztjx445dR588EHeffddFi1axMqVK9m/f7/bzNCioiJuvvlm8vPzWbNmDa+//jrx8fE88cQTpfaXkZFBdna282rUqFGF9LNaOe8nKIqIyAWXk5NjgK1cudLMzA4fPmyenp62aNEip8727dsNsLVr15qZ2XvvvWe1atWyAwcOOHX++c9/WkBAgJ08edLMzFJSUgywQ4cOVVxnqikdIYqIVAFHjhwBSh7WC7Bx40YKCgro1auXU6d169Y0adKEtWvXAiXPD2zfvj3BwcFOnT59+nD06FG++OILt+137NiR0NBQbrzxRlavXl3e3amWFIgiIpWsuLiYMWPGcO211zpPlD9w4AB16tRh/vz5dOjQgYCAAAICAvj+++9Zs2aNU+f0MASc96fOEYaGhvLiiy+yePFiFi9eTEREBDExMXz++ecV2MPqQQ8IFhGpIGe7QH7UqFGkp6fzySeflFonPDycKVOm0LJlS8yMmJgYkpKSSh0Bnk1UVBRRUVHO+27durF7925mzpzJG2+8ccH6VhMoEEVEKkBSUhJj4+LIzMpylkWGh9O6XTvS09NZtWoV4eHhTllISAj5+flER0dTr149Z7mnpyd169bl008/JSQkhM8++8xtP6dmoYaEhJy1LVdffXWZ4Xux05CpiEg5S0pKYuDAgbTPynJusr0GICuLDz74gPHjx9OsWTO3da688ko8PT1ZsWKFs+zLL79k7969FBQU0LVrV7p27cq2bdvIyclx6nz44YcEBATQtm3bs7Zn8+bNeuxTGXSEKCJSjoqKihgbF0c/M5L571HIG8AhoCswdfJkBgwYgIeHB4GBgXh7exMYGMiIESN46KGHOHz4MKNHj+bEiRN4eHjw9ttv07ZtW6Kiomjbti133HEHU6dO5cCBA/zlL39h1KhR1K1bF4BZs2bRrFkzLrvsMk6cOMGrr77Kxx9/zL///e9K+TyqMgWiiEg5SktLIzMri/m4D8n986f/rgXYv98ZLv1//+//cemll5Kdnc2AAQNwuVyMGzcOl8tFjx49uOyyyxg2bBgrV66kbdu2LF26lHvvvZeuXbvi6+vLsGHDePrpp5395OfnM3bsWPbt24ePjw8dOnTgo48+okePHhX0CVQfurm3iEg5mj9/PoMHDyYX8CujPJeSxzIlJCRQt27dMs8zTp892+2C/F69etG8eXNeeuml8m7+RUXnEEVEytGpc3XpZyk/tXznzp2lzjOuBdrv28fAgQNJSkpy1ikuLubkyZPl2OqLk44QRUTKUVFRES0iI2m/bx/JZm5HIcWUPL0+PSyMYjM67Nvndp4R4FEgDdgbGsq7773HwoUL+fvf/87y5cu58cYbK7AnNZ+OEEVEypGHhwfTZ89mKSXhd/rRX3+Xi6XA8JEj+WbfPv5M6S/l74CvgazsbHr06MH69esVhuVER4giIhWgrOsQm0VEMG3WLE6ePHnO5xkHDRpUQS2++GiWqYhIBYiNjeXWW28t8041qampQMn5xGvKWPfUeUZdO1i+dIQoIlLJzuk8Y3g4O/fswcPDo7KaWePpHKKISCU7l/OM02bNUhiWMwWiiEgVEBsbS2JiItvCwuhGyTnDbkB6eDiJiYlu1yFK+dCQqYhIFXK2J2JI+VMgioiIoCFTERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUREBFAgioiIAApEERERQIEoIiICKBBFREQABaKIiAigQBQREQEUiCIiIoACUUTkvMXExDBmzJhy3cfw4cPp379/ue5D3CkQRUREUCCKiIgACkQRkV/l0KFDDB06lPr16+Pj48NvfvMbdu7c6ZTHx8dTr149li9fTps2bfDz86Nv375kZ2c7dYqKinjooYeoV68eDRo04JFHHsHM3PZz8uRJHnjgARo1aoSXlxfXXXcd69evd8pTU1NxuVysWLGCzp074+PjQ7du3cjIyCj/D6GGUCCKiPwKw4cPZ8OGDbzzzjusXbsWM+Omm26ioKDAqXP8+HGmTZvGG2+8wapVq9i7dy8PP/ywUz59+nTi4+N57bXX+OSTT/jhhx9YsmSJ234eeeQRFi9ezOuvv87nn39OixYt6NOnDz/88INbvccff5zp06ezYcMGateuzZ133lm+H0BNYiIicl66d+9ucXFxtmPHDgNs9erVTtnBgwfN29vb3nrrLTMzmzt3rgG2a9cup86cOXMsODjYeR8aGmpTp0513hcUFFh4eLjdeuutZmaWl5dnnp6eNm/ePKdOfn6+NW7c2FkvJSXFAPvoo4+cOsuWLTPAfvzxxwv7AdRQtSs3jkVEqr6ioiLS0tLIzs4mNDTUGc7cvn07tWvXpkuXLk7dBg0aEBUVxfbt251lPj4+NG/e3HkfGhpKTk4OAEeOHCE7O9ttG7Vr16Zz587Ofnbv3k1BQQHXXnutU8fT05Orr77abT8AHTp0cNsPQE5ODk2aNPnVn0NNp0AUEfkZSUlJjI2LIzMry1lWt04d/P39ueGGG85pG56enm7vXS5XqXOEF8rp+3K5XAAUFxeXy75qGp1DFBE5i6SkJAYOHEj7rCzWArnAWsAvP59ly5axd+9eCgsLWbdunbPO999/T0ZGBm3btj2nfQQGBhIaGuq2jcLCQjZu3Oi8b968OXXq1GH16tXOsoKCAtavX3/O+5H/TUeIIiJlKCoqYmxcHP3MSOa/Rw/XAO2AvcCMqVP57W9/y8iRI3nppZfw9/fn0UcfJSwsjFtvvfWc9xUXF8eUKVNo2bIlrVu3ZsaMGRw+fNgp9/X15d5772XcuHEEBQXRpEkTpk6dyvHjxxkxYsQF6/PFToEoIlKGtLQ0MrOymE/ZQ2lXAW/95z/MnjOHRYsW0a9fP/Lz87n++ut57733Sg2T/pyxY8eSnZ3NsGHDqFWrFnfeeScDBgzgyJEjTp0pU6ZQXFzMHXfcQW5uLp07d2b58uXUr1//V/dVSrisvAayRUSqsfnz5zN48GByAb8yynOBACAhIYFBgwZVbOOkXOgcoohIGU7N0Ew/S3n6GfWk+tMRoohIGYqKimgRGUn7fftINnM7eigG+rtcpIeHs3PPHjw8PCqrmXIB6QhRRKQMHh4eTJ89m6WUhN/ps0z7u1wsBabNmqUwrEEUiCIiZxEbG0tiYiLbwsLoRsk5w25Aeng4iYmJxMbGVnIL5ULSkKmIyP9w5p1qoqOjdWRYAykQRURE0JCpiIgIoEAUEREBFIgiIiKAAlFERARQIIqIiAAKRBEREUCBKCIiAigQRUREAAWiiIgIoEAUEREBFIgiIiKAAlFERARQIIqIiAAKRBEREUCBKCIiAigQRUREAAWiiIgIoEAUEREBFIgiIiKAAlFERASA/w+r6S8/DLNNOQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}