{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiTheGreat/Intro-to-language-modeling/blob/main/Session_4_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb9584be-3f34-4db2-a817-97fa8ddb94e7",
      "metadata": {
        "id": "eb9584be-3f34-4db2-a817-97fa8ddb94e7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0cbf5dbc-f2bb-4289-a6c7-65f3b1d2ef96",
      "metadata": {
        "id": "0cbf5dbc-f2bb-4289-a6c7-65f3b1d2ef96"
      },
      "outputs": [],
      "source": [
        "emb = nn.Embedding(1000,16)\n",
        "hidde_size=32\n",
        "rnn = nn.LSTM(input_size=16, hidden_size=hidde_size, batch_first=True)\n",
        "out = nn.Linear(in_features=hidde_size, out_features=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8b061705-92f7-434e-9677-b78c0fca8f72",
      "metadata": {
        "id": "8b061705-92f7-434e-9677-b78c0fca8f72"
      },
      "outputs": [],
      "source": [
        "# A made-up example. We pretend that we have a batch of 1 text, with 4 integer-encoded words.\n",
        "test_input = torch.as_tensor([[7, 10, 5, 8]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2875657-8984-4664-90df-37aa1781646e",
      "metadata": {
        "id": "d2875657-8984-4664-90df-37aa1781646e",
        "outputId": "9cd94efa-1aa6-4f79-8f0e-0ce19062ef91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Apply the embedding\n",
        "emb_out = emb(test_input)\n",
        "\n",
        "# What is the shape?\n",
        "emb_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c13d2b1-884d-4cf6-b670-ce1ca3a42c56",
      "metadata": {
        "id": "8c13d2b1-884d-4cf6-b670-ce1ca3a42c56",
        "outputId": "9af82802-a428-4bd8-8edb-c56ff7e2627f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Apply the RNN\n",
        "# we need the first output\n",
        "rnn_out , rnn_last= rnn(emb_out)\n",
        "rnn_out.shape\n",
        "# What is the shape?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_last"
      ],
      "metadata": {
        "id": "7J2zaHii665j",
        "outputId": "864e1e9e-6b4c-40bd-ae49-54bafa525be9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7J2zaHii665j",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.2081,  0.0591,  0.0829, -0.1772, -0.0095,  0.0937, -0.1539,\n",
              "           -0.1977,  0.0167, -0.0609, -0.0748,  0.1566,  0.1843, -0.0310,\n",
              "           -0.1605,  0.0310,  0.2090,  0.1876, -0.0686,  0.0009,  0.0830,\n",
              "           -0.0906,  0.1314, -0.0090, -0.0551, -0.0247,  0.0064, -0.0266,\n",
              "           -0.2363, -0.1002, -0.0172, -0.0750]]], grad_fn=<StackBackward0>),\n",
              " tensor([[[ 0.3754,  0.1058,  0.2124, -0.3509, -0.0230,  0.1641, -0.3438,\n",
              "           -0.3530,  0.0313, -0.0995, -0.2353,  0.2866,  0.3388, -0.0655,\n",
              "           -0.2811,  0.0573,  0.5108,  0.3703, -0.1125,  0.0020,  0.1669,\n",
              "           -0.2234,  0.2534, -0.0172, -0.1357, -0.0559,  0.0123, -0.0442,\n",
              "           -0.3072, -0.2061, -0.0345, -0.1599]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a587e2f0-5eae-440b-92f3-6fe699632dfe",
      "metadata": {
        "id": "a587e2f0-5eae-440b-92f3-6fe699632dfe",
        "outputId": "23769472-7cac-458e-ba93-8b7ac70090ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Apply the word prediction unit\n",
        "token_pred = out(rnn_out)\n",
        "\n",
        "# What is the shape?\n",
        "token_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c9364b10-1acf-404f-824a-8a2d3c37d346",
      "metadata": {
        "id": "c9364b10-1acf-404f-824a-8a2d3c37d346"
      },
      "outputs": [],
      "source": [
        "# typically we use this for classifiers\n",
        "loss = nn.CrossEntropyLoss(ignore_index=0)\n",
        "# cross entropy expects target tensors to be one dimentional\n",
        "# when we compute the cross entropy loss, we don't want paddings to be taken into account and therfore we are going to ignore tokens with integer code zero, which in our case is the padding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a4e76d8b-fc46-4904-ae34-f4bcf3617b6c",
      "metadata": {
        "id": "a4e76d8b-fc46-4904-ae34-f4bcf3617b6c"
      },
      "outputs": [],
      "source": [
        "# NOTE: the target tensor is 1-dimensional!\n",
        "test_output = torch.as_tensor([10, 5, 8, 9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bad39ceb-fa51-4bc3-8406-f065c5aac986",
      "metadata": {
        "id": "bad39ceb-fa51-4bc3-8406-f065c5aac986",
        "outputId": "79445d43-cd3f-4d62-a421-23fc5192277a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.9254, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Apply the loss to the predicted output tensor and the target tensor. NOTE the shapes!\n",
        "#token_pred_2d_view=token_pred.view(-1, token_pred.shape[-1])\n",
        "#token_pred_2d_view=token_pred.view(1*4, 1000)\n",
        "loss(token_pred_2d_view, test_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}