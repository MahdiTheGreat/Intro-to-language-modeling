{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiTheGreat/Intro-to-language-modeling/blob/main/intro_to_language_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahdiTheGreat/Intro-to-language-modeling.git\n",
        "%cd Intro-to-language-modeling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXuQ-VlzuRv",
        "outputId": "d7c29141-5000-49a6-8269-d85bb3e4efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Intro-to-language-modeling'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 34 (delta 17), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 28.30 MiB | 24.17 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/Intro-to-language-modeling/Intro-to-language-modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "yO3xXRA_0ppt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eFpoOrObrug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3771ca0-15b8-457a-fc92-ec5178d4d84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
            "  Downloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
            "  Downloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, blis, thinc, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.4 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.0.1 numpy-2.0.2 spacy-3.8.2 thinc-8.3.2\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipdb\n",
        "!pip install -U spacy\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fv9gQcVafW3"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import ipdb\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxLmzqoUc339",
        "outputId": "f99efe95-66e1-456d-dd2d-12bcd2b13592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=2024):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(1998)"
      ],
      "metadata": {
        "id": "Qjj4IdOi08ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDybdl906rv",
        "outputId": "a3817812-1fed-4631-e759-09f3b0f47501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='lmdemo'\n",
        "zip_file = f\"{dataset}.zip\"\n",
        "!unzip -q $zip_file\n",
        "!rm $zip_file"
      ],
      "metadata": {
        "id": "IE8oAx8b3AWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(f'{dataset}/train.txt','r',encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "clFRaGPQ4Jc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_filepath=\"example.txt\""
      ],
      "metadata": {
        "id": "xDdQVDPjdCq_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "\n",
        "def get_token_counter(filepath,nlp,encoding):\n",
        "\n",
        "    buffer = \"\"  # Buffer to store partial sentences between lines\n",
        "    token_counter = Counter()\n",
        "\n",
        "    def sent_processor(sent,complete=True):\n",
        "     tokens=[]\n",
        "     if complete: tokens.append(nlp(\"BEGINNING\")[0])  # Add \"BEGINNING\" at the start of each sentence\n",
        "     tokens.extend([token for token in sent])  # Add sentence tokens\n",
        "     if complete: tokens.append(nlp(\"END\")[0])  # Add \"END\" at the end of each sentence\n",
        "     for token in tokens:\n",
        "      if not token.is_space:\n",
        "       token_counter[token.text.lower()] += 1\n",
        "\n",
        "\n",
        "    with open(filepath, 'r') as file:\n",
        "\n",
        "\n",
        "        for line in file:\n",
        "            # Add line to buffer and process with spaCy\n",
        "            buffer += \" \" + line.strip()\n",
        "            doc = nlp(buffer)\n",
        "            # Extract complete sentences\n",
        "            sentences = list(doc.sents)\n",
        "            for i, sent in enumerate(sentences):\n",
        "                # If it's not the last sentence, we print it as it's complete\n",
        "                if i < len(sentences) - 1:\n",
        "                    print(sent)\n",
        "                    sent_processor(sent)\n",
        "                else:\n",
        "                    # If it's the last sentence, store it in the buffer in case it's incomplete\n",
        "                    buffer = sent.text\n",
        "                    # Process sentences and identify complete sentences\n",
        "            for sent in doc.sents:\n",
        "                if sent.end_char < len(buffer):\n",
        "                    print(sent)\n",
        "                    sent_processor(sent)\n",
        "\n",
        "        # Process any remaining content in the buffer\n",
        "        doc = nlp(buffer)\n",
        "        for sent in doc.sents:\n",
        "         print(sent)\n",
        "         sent_processor(sent)\n",
        "\n",
        "    return token_counter\n",
        "\n",
        "# Load spaCy model for tokenization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class VocabularyBuilder:\n",
        "    def __init__(self, max_voc_size=None):\n",
        "        self.max_voc_size = max_voc_size\n",
        "        self.str_to_int = {}\n",
        "        self.int_to_str = {}\n",
        "        self.special_tokens = [\"BEGINNING\", \"END\", \"UNKNOWN\"]\n",
        "        self.token_counter = None\n",
        "\n",
        "\n",
        "    def build_vocabulary(self, filepath, nlp,token_counter_savepath=None,token_counter_loadpath=None,encoding=\"utf-8\"):\n",
        "\n",
        "        # Tokenize text and count tokens\n",
        "        if token_counter_loadpath is not None:\n",
        "         with open(token_counter_loadpath, \"r\") as file:\n",
        "            self.token_counter = Counter(json.load(file))\n",
        "        else:\n",
        "         self.token_counter =get_token_counter(filepath=filepath,nlp=nlp,encoding=encoding)\n",
        "\n",
        "        # Start vocabulary with special tokens\n",
        "        for idx, token in enumerate(self.special_tokens):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        # Select the most common tokens, considering max_voc_size - len(special_tokens)\n",
        "        if self.max_voc_size is None:\n",
        "            max_words = len(self.token_counter) - len(self.special_tokens)\n",
        "            self.max_voc_size = max_words + len(self.special_tokens)\n",
        "        else:\n",
        "         max_words = self.max_voc_size - len(self.special_tokens)\n",
        "        most_common_tokens = self.token_counter.most_common(max_words)\n",
        "\n",
        "        for idx, (token, _) in enumerate(most_common_tokens, start=len(self.special_tokens)):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        # Save to a JSON file\n",
        "        if token_counter_savepath is not None:\n",
        "         with open(token_counter_savepath, \"w\") as file:\n",
        "             json.dump(self.token_counter, file)\n",
        "\n",
        "\n",
        "    def get_token_id(self, token):\n",
        "        # Return the integer ID for a given token\n",
        "        return self.str_to_int.get(token.lower(), self.str_to_int[\"UNKNOWN\"])\n",
        "\n",
        "    def get_token_str(self, token_id):\n",
        "        # Return the original token string for a given integer ID\n",
        "        return self.int_to_str.get(token_id, \"UNKNOWN\")\n",
        "\n",
        "    def add_special_tokens_to_text(self, text):\n",
        "        \"\"\"\n",
        "        Tokenizes the text by sentence and adds special 'BEGINNING' and 'END' tokens\n",
        "        around each sentence.\n",
        "\n",
        "        Parameters:\n",
        "        - text (str): The input text.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of tokens with special 'BEGINNING' and 'END' tokens added.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    def sanity_check(self):\n",
        "        # Check vocabulary size\n",
        "        assert len(self.str_to_int) <= self.max_voc_size, \"Vocabulary size exceeds max_voc_size.\"\n",
        "\n",
        "        # Check special tokens exist and are unique\n",
        "        for token in self.special_tokens:\n",
        "            assert token in self.str_to_int, f\"Missing special token: {token}\"\n",
        "\n",
        "        # Check if highly frequent words are included and rare ones are not\n",
        "        common_words = [\"the\", \"and\"]\n",
        "        rare_words = [\"cuboidal\", \"epiglottis\"]\n",
        "\n",
        "        for word in common_words:\n",
        "            assert word in self.str_to_int, f\"Common word '{word}' not in vocabulary.\"\n",
        "\n",
        "        for word in rare_words:\n",
        "            assert word not in self.str_to_int, f\"Rare word '{word}' should not be in vocabulary.\"\n",
        "\n",
        "        # Check that mapping back and forth works for a test word\n",
        "        test_word = \"The\"\n",
        "        token_id = self.get_token_id(test_word)\n",
        "        assert self.get_token_str(token_id) == test_word.lower(), \"Round-trip token mapping failed.\"\n",
        "\n",
        "        print(\"Sanity check passed!\")\n",
        "\n",
        "token_counter_filepath=\"token_counter.json\"\n",
        "vocab_builder = VocabularyBuilder()\n",
        "vocab_builder.build_vocabulary(filepath=example_filepath, nlp=nlp,token_counter_savepath=token_counter_filepath)\n",
        "\n",
        "# Example mappings\n",
        "print(\"str_to_int:\", vocab_builder.str_to_int)\n",
        "print(\"int_to_str:\", vocab_builder.int_to_str)\n",
        "print(\"vocabulary size: \",len(vocab_builder.token_counter))\n",
        "\n",
        "# Convert a token to integer ID and back to string\n",
        "token_id = vocab_builder.get_token_id(\"example\")\n",
        "print(\"Token ID for 'example':\", token_id)\n",
        "print(\"Original token from ID:\", vocab_builder.get_token_str(token_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJ4k7STz96H",
        "outputId": "87188793-c5eb-4061-ab72-2db3a079e71c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Anatomy Anatomy (Greek anatomē, “dissection”) is the branch of biology concerned with the study of the structure of organisms and their parts.  \n",
            "Anatomy is a branch of natural science dealing with the structural organization of living things.  \n",
            "It is an old science, having its beginnings in prehistoric times.  \n",
            "Anatomy is inherently tied to embryology, comparative anatomy, evolutionary biology, and phylogeny, as these are the processes by which anatomy is generated over immediate (embryology) and long (evolution) timescales.  \n",
            "Human anatomy is one of the basic essential sciences of medicine.\n",
            "The discipline of anatomy is divided into macroscopic and microscopic anatomy.  \n",
            "Macroscopic anatomy, or gross anatomy, is the examination of an animal's body parts using unaided eyesight.  \n",
            "Gross anatomy also includes the branch of superficial anatomy.  \n",
            "Human anatomy is one of the basic essential sciences of medicine.\n",
            "The discipline of anatomy is divided into macroscopic and microscopic anatomy.  \n",
            "Microscopic anatomy involves the use of optical instruments in the study of the tissues of various structures, known as histology, and also in the study of cells.\n",
            "str_to_int: {'BEGINNING': 0, 'END': 1, 'UNKNOWN': 2, 'anatomy': 3, 'of': 4, 'the': 5, 'beginning': 6, '.': 7, 'end': 8, ',': 9, 'is': 10, 'and': 11, '(': 12, ')': 13, 'branch': 14, 'study': 15, 'in': 16, 'macroscopic': 17, 'microscopic': 18, 'biology': 19, 'with': 20, 'parts': 21, 'science': 22, 'an': 23, 'embryology': 24, 'as': 25, 'human': 26, 'one': 27, 'basic': 28, 'essential': 29, 'sciences': 30, 'medicine': 31, 'discipline': 32, 'divided': 33, 'into': 34, 'gross': 35, 'also': 36, 'greek': 37, 'anatomē': 38, '“': 39, 'dissection': 40, '”': 41, 'concerned': 42, 'structure': 43, 'organisms': 44, 'their': 45, 'a': 46, 'natural': 47, 'dealing': 48, 'structural': 49, 'organization': 50, 'living': 51, 'things': 52, 'it': 53, 'old': 54, 'having': 55, 'its': 56, 'beginnings': 57, 'prehistoric': 58, 'times': 59, 'inherently': 60, 'tied': 61, 'to': 62, 'comparative': 63, 'evolutionary': 64, 'phylogeny': 65, 'these': 66, 'are': 67, 'processes': 68, 'by': 69, 'which': 70, 'generated': 71, 'over': 72, 'immediate': 73, 'long': 74, 'evolution': 75, 'timescales': 76, 'or': 77, 'examination': 78, 'animal': 79, \"'s\": 80, 'body': 81, 'using': 82, 'unaided': 83, 'eyesight': 84, 'includes': 85, 'superficial': 86, 'involves': 87, 'use': 88, 'optical': 89, 'instruments': 90, 'tissues': 91, 'various': 92, 'structures': 93}\n",
            "int_to_str: {0: 'BEGINNING', 1: 'END', 2: 'UNKNOWN', 3: 'anatomy', 4: 'of', 5: 'the', 6: 'beginning', 7: '.', 8: 'end', 9: ',', 10: 'is', 11: 'and', 12: '(', 13: ')', 14: 'branch', 15: 'study', 16: 'in', 17: 'macroscopic', 18: 'microscopic', 19: 'biology', 20: 'with', 21: 'parts', 22: 'science', 23: 'an', 24: 'embryology', 25: 'as', 26: 'human', 27: 'one', 28: 'basic', 29: 'essential', 30: 'sciences', 31: 'medicine', 32: 'discipline', 33: 'divided', 34: 'into', 35: 'gross', 36: 'also', 37: 'greek', 38: 'anatomē', 39: '“', 40: 'dissection', 41: '”', 42: 'concerned', 43: 'structure', 44: 'organisms', 45: 'their', 46: 'a', 47: 'natural', 48: 'dealing', 49: 'structural', 50: 'organization', 51: 'living', 52: 'things', 53: 'it', 54: 'old', 55: 'having', 56: 'its', 57: 'beginnings', 58: 'prehistoric', 59: 'times', 60: 'inherently', 61: 'tied', 62: 'to', 63: 'comparative', 64: 'evolutionary', 65: 'phylogeny', 66: 'these', 67: 'are', 68: 'processes', 69: 'by', 70: 'which', 71: 'generated', 72: 'over', 73: 'immediate', 74: 'long', 75: 'evolution', 76: 'timescales', 77: 'or', 78: 'examination', 79: 'animal', 80: \"'s\", 81: 'body', 82: 'using', 83: 'unaided', 84: 'eyesight', 85: 'includes', 86: 'superficial', 87: 'involves', 88: 'use', 89: 'optical', 90: 'instruments', 91: 'tissues', 92: 'various', 93: 'structures'}\n",
            "vocabulary size:  94\n",
            "Token ID for 'example': 2\n",
            "Original token from ID: UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_counter_filepath=\"token_counter.json\"\n",
        "vocab_builder = VocabularyBuilder()\n",
        "vocab_builder.build_vocabulary(filepath=example_filepath, nlp=nlp,token_counter_loadpath=token_counter_filepath)\n",
        "\n",
        "# Example mappings\n",
        "print(\"str_to_int:\", vocab_builder.str_to_int)\n",
        "print(\"int_to_str:\", vocab_builder.int_to_str)\n",
        "print(\"vocabulary size: \",len(vocab_builder.token_counter))\n",
        "\n",
        "\n",
        "# Convert a token to integer ID and back to string\n",
        "token_id = vocab_builder.get_token_id(\"example\")\n",
        "print(\"Token ID for 'example':\", token_id)\n",
        "print(\"Original token from ID:\", vocab_builder.get_token_str(token_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA1UytBVGKT8",
        "outputId": "643c619f-8eb4-43cb-d316-cc5cd752d86a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "str_to_int: {'BEGINNING': 0, 'END': 1, 'UNKNOWN': 2, 'anatomy': 3, 'of': 4, 'the': 5, 'beginning': 6, '.': 7, 'end': 8, ',': 9, 'is': 10, 'and': 11, '(': 12, ')': 13, 'branch': 14, 'study': 15, 'in': 16, 'macroscopic': 17, 'microscopic': 18, 'biology': 19, 'with': 20, 'parts': 21, 'science': 22, 'an': 23, 'embryology': 24, 'as': 25, 'human': 26, 'one': 27, 'basic': 28, 'essential': 29, 'sciences': 30, 'medicine': 31, 'discipline': 32, 'divided': 33, 'into': 34, 'gross': 35, 'also': 36, 'greek': 37, 'anatomē': 38, '“': 39, 'dissection': 40, '”': 41, 'concerned': 42, 'structure': 43, 'organisms': 44, 'their': 45, 'a': 46, 'natural': 47, 'dealing': 48, 'structural': 49, 'organization': 50, 'living': 51, 'things': 52, 'it': 53, 'old': 54, 'having': 55, 'its': 56, 'beginnings': 57, 'prehistoric': 58, 'times': 59, 'inherently': 60, 'tied': 61, 'to': 62, 'comparative': 63, 'evolutionary': 64, 'phylogeny': 65, 'these': 66, 'are': 67, 'processes': 68, 'by': 69, 'which': 70, 'generated': 71, 'over': 72, 'immediate': 73, 'long': 74, 'evolution': 75, 'timescales': 76, 'or': 77, 'examination': 78, 'animal': 79, \"'s\": 80, 'body': 81, 'using': 82, 'unaided': 83, 'eyesight': 84, 'includes': 85, 'superficial': 86, 'involves': 87, 'use': 88, 'optical': 89, 'instruments': 90, 'tissues': 91, 'various': 92, 'structures': 93}\n",
            "int_to_str: {0: 'BEGINNING', 1: 'END', 2: 'UNKNOWN', 3: 'anatomy', 4: 'of', 5: 'the', 6: 'beginning', 7: '.', 8: 'end', 9: ',', 10: 'is', 11: 'and', 12: '(', 13: ')', 14: 'branch', 15: 'study', 16: 'in', 17: 'macroscopic', 18: 'microscopic', 19: 'biology', 20: 'with', 21: 'parts', 22: 'science', 23: 'an', 24: 'embryology', 25: 'as', 26: 'human', 27: 'one', 28: 'basic', 29: 'essential', 30: 'sciences', 31: 'medicine', 32: 'discipline', 33: 'divided', 34: 'into', 35: 'gross', 36: 'also', 37: 'greek', 38: 'anatomē', 39: '“', 40: 'dissection', 41: '”', 42: 'concerned', 43: 'structure', 44: 'organisms', 45: 'their', 46: 'a', 47: 'natural', 48: 'dealing', 49: 'structural', 50: 'organization', 51: 'living', 52: 'things', 53: 'it', 54: 'old', 55: 'having', 56: 'its', 57: 'beginnings', 58: 'prehistoric', 59: 'times', 60: 'inherently', 61: 'tied', 62: 'to', 63: 'comparative', 64: 'evolutionary', 65: 'phylogeny', 66: 'these', 67: 'are', 68: 'processes', 69: 'by', 70: 'which', 71: 'generated', 72: 'over', 73: 'immediate', 74: 'long', 75: 'evolution', 76: 'timescales', 77: 'or', 78: 'examination', 79: 'animal', 80: \"'s\", 81: 'body', 82: 'using', 83: 'unaided', 84: 'eyesight', 85: 'includes', 86: 'superficial', 87: 'involves', 88: 'use', 89: 'optical', 90: 'instruments', 91: 'tissues', 92: 'various', 93: 'structures'}\n",
            "vocabulary size:  94\n",
            "Token ID for 'example': 2\n",
            "Original token from ID: UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform sanity check\n",
        "vocab_builder.sanity_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1sB4W8Q0Qo9",
        "outputId": "40306d49-0dec-4db4-ef21-ca7913c6ab33"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "class TrainingDataPreparer:\n",
        "    def __init__(self, vocab_builder, nlp, context_window_size=3, chunk_size=1024):\n",
        "        self.vocab_builder = vocab_builder\n",
        "        self.context_window_size = context_window_size\n",
        "        self.chunk_size = chunk_size\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def encode_token(self, token):\n",
        "        token_id = self.vocab_builder.get_token_id(token.text)\n",
        "        return token_id if token_id != self.vocab_builder.get_token_id(\"UNKNOWN\") else None\n",
        "\n",
        "    def prepare_training_data(self, input_file, output_file):\n",
        "        with open(input_file, \"r\") as infile, open(output_file, \"w\", newline=\"\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow([f\"Token_{i+1}\" for i in range(self.context_window_size)] + [\"Target\"])\n",
        "\n",
        "            # Initialize the beginning padding tokens\n",
        "            padded_tokens = [self.vocab_builder.get_token_id(\"BEGINNING\")] * self.context_window_size\n",
        "            first_chunk = True\n",
        "\n",
        "            while True:\n",
        "                chunk = infile.read(self.chunk_size)\n",
        "                if not chunk:\n",
        "                    break\n",
        "\n",
        "                # Tokenize chunk into sentences\n",
        "                doc = self.nlp(chunk)\n",
        "                sentences = list(doc.sents)\n",
        "\n",
        "                for sentence in sentences:\n",
        "                    # Process sentence and convert to token IDs, skipping unknowns and spaces\n",
        "                    sentence_token_ids = [\n",
        "                        self.encode_token(token) for token in sentence if self.encode_token(token) is not None\n",
        "                    ]\n",
        "\n",
        "                    if first_chunk and sentence_token_ids:\n",
        "                        padded_tokens += sentence_token_ids\n",
        "                        first_chunk = False\n",
        "                    else:\n",
        "                        # Add only the sentence tokens from subsequent sentences\n",
        "                        padded_tokens.extend(sentence_token_ids)\n",
        "\n",
        "                    # Add END token at the end of each sentence\n",
        "                    padded_tokens.append(self.vocab_builder.get_token_id(\"END\"))\n",
        "\n",
        "                    # Generate context-target sequences\n",
        "                    for i in range(len(padded_tokens) - self.context_window_size):\n",
        "                        context = padded_tokens[i:i + self.context_window_size]\n",
        "                        target = padded_tokens[i + self.context_window_size]\n",
        "                        writer.writerow(context + [target])\n",
        "\n",
        "                # Retain only the last context window tokens for the next chunk\n",
        "                padded_tokens = padded_tokens[-self.context_window_size:]\n",
        "\n",
        "        print(\"Training data preparation complete.\")\n",
        "\n",
        "    def print_csv_as_words(self, csv_file):\n",
        "           \"\"\"\n",
        "           Reads a CSV file with token IDs, decodes them to words, and prints each sequence.\n",
        "           \"\"\"\n",
        "           with open(csv_file, \"r\") as file:\n",
        "               reader = csv.reader(file)\n",
        "               headers = next(reader)  # Skip the header\n",
        "\n",
        "               for row in reader:\n",
        "                   context_ids = row[:-1]  # All columns except the last one are context\n",
        "                   target_id = row[-1]  # Last column is the target\n",
        "\n",
        "                   # Convert token IDs to words\n",
        "                   context_words = [self.vocab_builder.get_token_str(int(token_id)) for token_id in context_ids]\n",
        "                   target_word = self.vocab_builder.get_token_str(int(target_id))\n",
        "\n",
        "                   # Print context and target as words\n",
        "                   print(\"Context:\", context_words, \"-> Target:\", target_word)\n",
        "\n",
        "\n",
        "data_preparer = TrainingDataPreparer(vocab_builder=vocab_builder,nlp=nlp, context_window_size=3)\n",
        "\n",
        "input_file = \"example.txt\"\n",
        "output_file = \"training_sequences.csv\"\n",
        "\n",
        "# Prepare training data\n",
        "data_preparer.prepare_training_data(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "uXLrr6YeF0AF",
        "outputId": "02a53360-ec40-4df6-d234-dee1d4799f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=pd.read_csv(\"training_sequences.csv\")\n",
        "print(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXru39twOD3D",
        "outputId": "ae942332-1093-407c-aff1-90acee772228"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Token_1  Token_2  Token_3  Target\n",
            "0          6        6        6       3\n",
            "1          6        6        3       3\n",
            "2          6        3        3      12\n",
            "3          3        3       12      37\n",
            "4          3       12       37      38\n",
            "..       ...      ...      ...     ...\n",
            "954       11       36       16       5\n",
            "955       36       16        5      15\n",
            "956       16        5       15       4\n",
            "957        5       15        4       7\n",
            "958       15        4        7       8\n",
            "\n",
            "[959 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_preparer.print_csv_as_words(\"training_sequences.csv\")"
      ],
      "metadata": {
        "id": "-lrw_0GDqMbU",
        "outputId": "9e3cb842-0599-48f5-f4fe-148407b5da68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['eyesight', '.', 'end'] -> Target: gross\n",
            "Context: ['.', 'end', 'gross'] -> Target: anatomy\n",
            "Context: ['end', 'gross', 'anatomy'] -> Target: also\n",
            "Context: ['gross', 'anatomy', 'also'] -> Target: includes\n",
            "Context: ['anatomy', 'also', 'includes'] -> Target: the\n",
            "Context: ['also', 'includes', 'the'] -> Target: branch\n",
            "Context: ['includes', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: superficial\n",
            "Context: ['branch', 'of', 'superficial'] -> Target: anatomy\n",
            "Context: ['of', 'superficial', 'anatomy'] -> Target: .\n",
            "Context: ['superficial', 'anatomy', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['eyesight', '.', 'end'] -> Target: gross\n",
            "Context: ['.', 'end', 'gross'] -> Target: anatomy\n",
            "Context: ['end', 'gross', 'anatomy'] -> Target: also\n",
            "Context: ['gross', 'anatomy', 'also'] -> Target: includes\n",
            "Context: ['anatomy', 'also', 'includes'] -> Target: the\n",
            "Context: ['also', 'includes', 'the'] -> Target: branch\n",
            "Context: ['includes', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: superficial\n",
            "Context: ['branch', 'of', 'superficial'] -> Target: anatomy\n",
            "Context: ['of', 'superficial', 'anatomy'] -> Target: .\n",
            "Context: ['superficial', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: microscopic\n",
            "Context: ['.', 'end', 'microscopic'] -> Target: anatomy\n",
            "Context: ['end', 'microscopic', 'anatomy'] -> Target: involves\n",
            "Context: ['microscopic', 'anatomy', 'involves'] -> Target: the\n",
            "Context: ['anatomy', 'involves', 'the'] -> Target: use\n",
            "Context: ['involves', 'the', 'use'] -> Target: of\n",
            "Context: ['the', 'use', 'of'] -> Target: optical\n",
            "Context: ['use', 'of', 'optical'] -> Target: instruments\n",
            "Context: ['of', 'optical', 'instruments'] -> Target: in\n",
            "Context: ['optical', 'instruments', 'in'] -> Target: the\n",
            "Context: ['instruments', 'in', 'the'] -> Target: study\n",
            "Context: ['in', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: tissues\n",
            "Context: ['of', 'the', 'tissues'] -> Target: of\n",
            "Context: ['the', 'tissues', 'of'] -> Target: various\n",
            "Context: ['tissues', 'of', 'various'] -> Target: structures\n",
            "Context: ['of', 'various', 'structures'] -> Target: ,\n",
            "Context: ['various', 'structures', ','] -> Target: as\n",
            "Context: ['structures', ',', 'as'] -> Target: ,\n",
            "Context: [',', 'as', ','] -> Target: and\n",
            "Context: ['as', ',', 'and'] -> Target: also\n",
            "Context: [',', 'and', 'also'] -> Target: in\n",
            "Context: ['and', 'also', 'in'] -> Target: the\n",
            "Context: ['also', 'in', 'the'] -> Target: study\n",
            "Context: ['in', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: .\n",
            "Context: ['study', 'of', '.'] -> Target: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a tensor dataset ##\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def TorchDataLoader(training_sequences, batch_size):\n",
        "  context_words = [item[0] for item in training_sequences]  # List of [context]\n",
        "  target_words = [item[1] for item in training_sequences]   # List of target words\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  context_tensor = torch.tensor(context_words, dtype=torch.long)  # Shape: (num_samples, 3)\n",
        "  target_tensor = torch.tensor(target_words, dtype=torch.long)    # Shape: (num_samples,)\n",
        "\n",
        "  # Create a TensorDataset\n",
        "  dataset = TensorDataset(context_tensor, target_tensor)\n",
        "\n",
        "  # Create a DataLoader for batching\n",
        "  batch_size = 4\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Iterate over the DataLoader\n",
        "  for batch_context, batch_target in dataloader:\n",
        "      print(\"Batch context:\", batch_context)\n",
        "      print(\"Batch target:\", batch_target)\n",
        "      # You can now use batch_context and batch_target for model training\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "aM8fZiApXo14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SimpleANN(nn.Module):\n",
        "\n",
        "    def __init__(self,layer_sizes,activation=nn.ReLU,last_layer_activation=nn.ReLU,dropout=0):\n",
        "\n",
        "        super(SimpleANN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(layer_sizes)-2):\n",
        "          self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
        "          self.layers.append(nn.Dropout(dropout))\n",
        "          self.layers.append(activation())\n",
        "\n",
        "        self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
        "        if last_layer_activation is not None:\n",
        "         self.layers.append(nn.Dropout(dropout))\n",
        "         self.layers.append(last_layer_activation())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, np.prod(x.shape[1:])) # Flatten the input\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RFgjvuVxXyh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "def dense_arch_builder(input_size,scale_factor=0,hidden_layers_num=0,repeat=0,output_size=1):\n",
        "  layer_sizes=[input_size]\n",
        "\n",
        "  if scale_factor!=0:\n",
        "\n",
        "   if scale_factor>1:\n",
        "    for i in range(hidden_layers_num):\n",
        "     layer_sizes.append(layer_sizes[-1]*scale_factor)\n",
        "    while layer_sizes[-1]<output_size:\n",
        "     layer_sizes.append(layer_sizes[-1]*scale_factor)\n",
        "\n",
        "   elif scale_factor==1:\n",
        "     for i in range(2,hidden_layers_num+2):\n",
        "      layer_sizes.append(layer_sizes[0]*i)\n",
        "     i+=1\n",
        "     while layer_sizes[-1]<output_size:\n",
        "      layer_sizes.append(layer_sizes[0]*i)\n",
        "      i+=1\n",
        "\n",
        "   mirrored_layer_sizes=deepcopy(layer_sizes)\n",
        "   mirrored_layer_sizes.reverse()\n",
        "   mirrored_layer_sizes=mirrored_layer_sizes[1:-1]\n",
        "\n",
        "   for i in range(repeat):\n",
        "    layer_sizes.append(layer_sizes[-1])\n",
        "\n",
        "   if output_size>0:\n",
        "    layer_sizes+=mirrored_layer_sizes\n",
        "    downscale_factor=scale_factor if scale_factor>1 else 2\n",
        "\n",
        "    while layer_sizes[-1]!=output_size:\n",
        "     if layer_sizes[-1]//downscale_factor>=output_size:\n",
        "      layer_sizes.append(layer_sizes[-1]//downscale_factor)\n",
        "     else:\n",
        "      layer_sizes.append(output_size)\n",
        "\n",
        "  else:\n",
        "    downscale_factor = (input_size / output_size) ** (1 / hidden_layers_num)\n",
        "    for i in range(hidden_layers_num):\n",
        "        layer_sizes.append(int(input_size / (downscale_factor ** i)))\n",
        "    layer_sizes.append(output_size)\n",
        "\n",
        "  return layer_sizes\n"
      ],
      "metadata": {
        "id": "YZ2hnRbQX-bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot the training metrics\n",
        "\n",
        "def plot_training_metrics(train_acc, val_acc, train_loss, title, save_path):\n",
        "    # Ensure that all input lists have the same length\n",
        "    assert len(train_acc) == len(val_acc) == len(train_loss), \"All input histories must have the same length.\"\n",
        "\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "    # Create the metrics DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        'Epoch': epochs,\n",
        "        'Training Accuracy (%)': train_acc,\n",
        "        'Validation Accuracy (%)': val_acc,\n",
        "        'Training Loss': train_loss\n",
        "    })\n",
        "\n",
        "    # Initialize the plot\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Training and Validation Accuracy on ax1\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy (%)', color=color)\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Training Accuracy (%)'], label='Train Acc', color='tab:blue')\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Validation Accuracy (%)'], label='Val Acc', color='tab:cyan')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Create a second y-axis for Training Loss\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Loss', color=color)\n",
        "    ax2.plot(df_metrics['Epoch'], df_metrics['Training Loss'], label='Train Loss', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
        "\n",
        "    # Set plot title and layout\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and display the plot\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aaXic0GgbFbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcS/kUcYX/ZKW0TPyKUGOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}