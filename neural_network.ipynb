{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiTheGreat/Intro-to-language-modeling/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb\n",
        "!pip install -U spacy\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhVjlxLwJhiu",
        "outputId": "46f9f6c3-d27c-46d3-9e2b-bdc0490f7f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
            "  Downloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
            "  Downloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, blis, thinc, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.5\n",
            "    Uninstalling spacy-3.7.5:\n",
            "      Successfully uninstalled spacy-3.7.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "langchain 0.3.4 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.0.1 numpy-2.0.2 spacy-3.8.2 thinc-8.3.2\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import ipdb\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "# %pdb on"
      ],
      "metadata": {
        "id": "v6kGb9T7JfDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot the training metrics\n",
        "\n",
        "def plot_training_metrics(train_acc, val_acc, train_loss, title, save_path):\n",
        "    # Ensure that all input lists have the same length\n",
        "    assert len(train_acc) == len(val_acc) == len(train_loss), \"All input histories must have the same length.\"\n",
        "\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "    # Create the metrics DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        'Epoch': epochs,\n",
        "        'Training Accuracy (%)': train_acc,\n",
        "        'Validation Accuracy (%)': val_acc,\n",
        "        'Training Loss': train_loss\n",
        "    })\n",
        "\n",
        "    # Initialize the plot\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Training and Validation Accuracy on ax1\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy (%)', color=color)\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Training Accuracy (%)'], label='Train Acc', color='tab:blue')\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Validation Accuracy (%)'], label='Val Acc', color='tab:cyan')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Create a second y-axis for Training Loss\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Loss', color=color)\n",
        "    ax2.plot(df_metrics['Epoch'], df_metrics['Training Loss'], label='Train Loss', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
        "\n",
        "    # Set plot title and layout\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and display the plot\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "B2pWU-GXJb7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SimpleANN(nn.Module):\n",
        "\n",
        "    def __init__(self,layer_sizes,activation=nn.ReLU,last_layer_activation=nn.Softmax,dropout=0):\n",
        "\n",
        "        super(SimpleANN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(layer_sizes)-2):\n",
        "          self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
        "          self.layers.append(nn.Dropout(dropout))\n",
        "          self.layers.append(activation())\n",
        "\n",
        "        self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
        "        if last_layer_activation is not None:\n",
        "         self.layers.append(nn.Dropout(dropout))\n",
        "         self.layers.append(last_layer_activation())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, np.prod(x.shape[1:])) # Flatten the input\n",
        "        x = x.float()\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5dT0NfEsJQri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=2024):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(1998)"
      ],
      "metadata": {
        "id": "3im355-CJNEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh2mGMOHJLVf",
        "outputId": "21b60cb9-efa1-4757-a9c0-a3f46354c399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "def dense_arch_builder(input_size,scale_factor=0,hidden_layers_num=0,repeat=0,output_size=1):\n",
        "  layer_sizes=[input_size]\n",
        "\n",
        "  if scale_factor!=0:\n",
        "\n",
        "   if scale_factor>1:\n",
        "    for i in range(hidden_layers_num):\n",
        "     layer_sizes.append(layer_sizes[-1]*scale_factor)\n",
        "    while layer_sizes[-1]<output_size:\n",
        "     layer_sizes.append(layer_sizes[-1]*scale_factor)\n",
        "\n",
        "   elif scale_factor==1:\n",
        "     for i in range(2,hidden_layers_num+2):\n",
        "      layer_sizes.append(layer_sizes[0]*i)\n",
        "     i+=1\n",
        "     while layer_sizes[-1]<output_size:\n",
        "      layer_sizes.append(layer_sizes[0]*i)\n",
        "      i+=1\n",
        "\n",
        "   mirrored_layer_sizes=deepcopy(layer_sizes)\n",
        "   mirrored_layer_sizes.reverse()\n",
        "   mirrored_layer_sizes=mirrored_layer_sizes[1:-1]\n",
        "\n",
        "   for i in range(repeat):\n",
        "    layer_sizes.append(layer_sizes[-1])\n",
        "\n",
        "   if output_size>0:\n",
        "    layer_sizes+=mirrored_layer_sizes\n",
        "    downscale_factor=scale_factor if scale_factor>1 else 2\n",
        "\n",
        "    while layer_sizes[-1]!=output_size:\n",
        "     if layer_sizes[-1]//downscale_factor>=output_size:\n",
        "      layer_sizes.append(layer_sizes[-1]//downscale_factor)\n",
        "     else:\n",
        "      layer_sizes.append(output_size)\n",
        "\n",
        "  else:\n",
        "    downscale_factor = (input_size / output_size) ** (1 / hidden_layers_num)\n",
        "    for i in range(hidden_layers_num):\n",
        "        layer_sizes.append(int(input_size / (downscale_factor ** i)))\n",
        "    layer_sizes.append(output_size)\n",
        "\n",
        "  return layer_sizes\n"
      ],
      "metadata": {
        "id": "AHggv8hkax0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes=dense_arch_builder(input_size=3,scale_factor=2,hidden_layers_num=3,repeat=0,output_size=10)\n",
        "print(layer_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ELDJdA3a0DS",
        "outputId": "8037f015-f943-4801-ef4b-890a704e19f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 6, 12, 24, 12, 6, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rdFEcIZI2c2"
      },
      "outputs": [],
      "source": [
        "## Creating a tensor dataset ##\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def TorchDataLoader(training_sequences, batch_size):\n",
        "  context_words = [item[0] for item in training_sequences]  # List of [context]\n",
        "  target_words = [item[1] for item in training_sequences]   # List of target words\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  context_tensor = torch.tensor(context_words, dtype=torch.long)  # Shape: (num_samples, 3)\n",
        "  target_tensor = torch.tensor(target_words, dtype=torch.long)    # Shape: (num_samples,)\n",
        "\n",
        "  # Create a TensorDataset\n",
        "  dataset = TensorDataset(context_tensor, target_tensor)\n",
        "\n",
        "  # Create a DataLoader for batching\n",
        "  batch_size = 4\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # Iterate over the DataLoader\n",
        "  for batch_context, batch_target in dataloader:\n",
        "      print(\"Batch context:\", batch_context)\n",
        "      print(\"Batch target:\", batch_target)\n",
        "      # You can now use batch_context and batch_target for model training\n",
        "\n",
        "  return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_text = [\n",
        "    ([2, 2, 2], 7), ([2, 2, 7], 8), ([2, 7, 8], 3), ([7, 8, 3], 9),\n",
        "    ([8, 3, 9], 4), ([3, 9, 4], 5), ([9, 4, 5], 2), ([2, 2, 2], 2),\n",
        "    ([2, 2, 2], 12), ([2, 2, 12], 4), ([2, 12, 4], 5), ([12, 4, 5], 13),\n",
        "    ([4, 5, 13], 3), ([5, 13, 3], 14), ([13, 3, 14], 15), ([3, 14, 15], 2),\n",
        "    ([2, 2, 2], 6), ([2, 2, 6], 16), ([2, 6, 16], 17), ([6, 16, 17], 18),\n",
        "    ([16, 17, 18], 19), ([17, 18, 19], 20), ([18, 19, 20], 6), ([19, 20, 6], 21),\n",
        "    ([20, 6, 21], 22), ([6, 21, 22], 2)\n",
        "]\n",
        "\n",
        "dataloader = TorchDataLoader(dummy_text, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZU_rYRWKl4I",
        "outputId": "01c51815-d2e3-438b-9c74-ee25fef76aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch context: tensor([[ 2,  2,  2],\n",
            "        [ 2,  2, 12],\n",
            "        [ 3,  9,  4],\n",
            "        [12,  4,  5]])\n",
            "Batch target: tensor([ 2,  4,  5, 13])\n",
            "Batch context: tensor([[18, 19, 20],\n",
            "        [16, 17, 18],\n",
            "        [ 2,  2,  7],\n",
            "        [ 2,  2,  2]])\n",
            "Batch target: tensor([ 6, 19,  8,  6])\n",
            "Batch context: tensor([[ 8,  3,  9],\n",
            "        [ 6, 21, 22],\n",
            "        [ 7,  8,  3],\n",
            "        [ 2,  2,  2]])\n",
            "Batch target: tensor([ 4,  2,  9, 12])\n",
            "Batch context: tensor([[ 4,  5, 13],\n",
            "        [17, 18, 19],\n",
            "        [13,  3, 14],\n",
            "        [ 2,  6, 16]])\n",
            "Batch target: tensor([ 3, 20, 15, 17])\n",
            "Batch context: tensor([[ 5, 13,  3],\n",
            "        [ 6, 16, 17],\n",
            "        [20,  6, 21],\n",
            "        [ 3, 14, 15]])\n",
            "Batch target: tensor([14, 18, 22,  2])\n",
            "Batch context: tensor([[19, 20,  6],\n",
            "        [ 9,  4,  5],\n",
            "        [ 2,  7,  8],\n",
            "        [ 2,  2,  2]])\n",
            "Batch target: tensor([21,  2,  3,  7])\n",
            "Batch context: tensor([[ 2, 12,  4],\n",
            "        [ 2,  2,  6]])\n",
            "Batch target: tensor([ 5, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3,64,24]\n",
        "\n",
        "model = SimpleANN(layer_sizes=layer_sizes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "number_of_epochs = 30\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "    for batch_context, batch_target in dataloader:\n",
        "        print(dataloader)\n",
        "        #FORWARD PASS:\n",
        "        X = batch_context\n",
        "        Y = batch_target\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        outputs = model(X)  # Model output for X\n",
        "        loss = criterion(outputs, Y) # Compute the loss between model output and Y\n",
        "\n",
        "        #BACKWARD PASS (updating the model parameters):\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()        # Compute gradients\n",
        "        optimizer.step()       # Update model parameters\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{number_of_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvWa59nZJCps",
        "outputId": "4b0a69ca-3a34-48d1-e96d-2cc94e61eda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [1/30], Loss: 3.1898\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [2/30], Loss: 3.2218\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [3/30], Loss: 3.0364\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [4/30], Loss: 3.1126\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [5/30], Loss: 3.0601\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [6/30], Loss: 3.1882\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [7/30], Loss: 3.0330\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [8/30], Loss: 3.2198\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [9/30], Loss: 3.2108\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [10/30], Loss: 3.1952\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [11/30], Loss: 2.8021\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [12/30], Loss: 3.0307\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [13/30], Loss: 3.1947\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [14/30], Loss: 2.7337\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [15/30], Loss: 3.0160\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [16/30], Loss: 3.0683\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [17/30], Loss: 2.7482\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [18/30], Loss: 3.0880\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [19/30], Loss: 3.1742\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [20/30], Loss: 2.8348\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [21/30], Loss: 2.7440\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [22/30], Loss: 3.1510\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [23/30], Loss: 2.9962\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [24/30], Loss: 2.7590\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [25/30], Loss: 2.9790\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [26/30], Loss: 3.2001\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [27/30], Loss: 2.9164\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [28/30], Loss: 3.0718\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [29/30], Loss: 3.1418\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7cc5998036a0>\n",
            "Epoch [30/30], Loss: 2.8314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "9vZmEKXlP7vD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the next word for four sentences:"
      ],
      "metadata": {
        "id": "ak9bYCH7QEtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = torch.tensor([[0, 13, 12],\n",
        "                              [0, 8, 9],\n",
        "                              [8, 7, 6],\n",
        "                              [5, 4, 5]])\n",
        "output = model(test_sentences).detach().numpy()\n",
        "\n",
        "# Predict\n",
        "predictions = np.argmax(output, axis=1)\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "plbd92dQP7d-",
        "outputId": "a017435a-3fc4-4dbf-e31c-98d112fffcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 13, 12]\n",
            "5\n",
            "[0, 8, 9]\n",
            "3\n",
            "[8, 7, 6]\n",
            "13\n",
            "[5, 4, 5]\n",
            "13\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantitative evaluation"
      ],
      "metadata": {
        "id": "JfO60jvqTjdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict validation data\n",
        "dummy_val = [\n",
        "    ([2, 2, 2], 7), ([2, 2, 7], 8), ([2, 7, 8], 3), ([7, 8, 3], 9),\n",
        "    ([8, 3, 9], 4), ([3, 9, 4], 5), ([9, 4, 5], 2), ([2, 2, 2], 2),\n",
        "    ([2, 2, 2], 12), ([2, 2, 12], 4), ([2, 12, 4], 5), ([12, 4, 5], 13),\n",
        "    ([4, 5, 13], 3), ([5, 13, 3], 14), ([13, 3, 14], 15), ([3, 14, 15], 2),\n",
        "    ([2, 2, 2], 6), ([2, 2, 6], 16), ([2, 6, 16], 17), ([6, 16, 17], 18),\n",
        "    ([16, 17, 18], 19), ([17, 18, 19], 20), ([18, 19, 20], 6), ([19, 20, 6], 21),\n",
        "    ([20, 6, 21], 22), ([6, 21, 22], 2)\n",
        "]\n",
        "val_dataloader = TorchDataLoader(dummy_val, 4)\n",
        "loss = []\n",
        "for batch_context, batch_target in val_dataloader:\n",
        "        #FORWARD PASS:\n",
        "        X = batch_context\n",
        "        Y = batch_target\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        outputs = (model(X))  # Model output for X\n",
        "        loss.append((criterion(outputs, Y)).item()) # Compute the loss between model output and Y\n",
        "\n",
        "# Compute perplexity\n",
        "perplexity = np.exp(np.mean(loss))\n",
        "print(perplexity)"
      ],
      "metadata": {
        "id": "5xfNYfZ7Ti5i",
        "outputId": "b4349a9c-8994-4866-b222-e477c9867321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch context: tensor([[ 6, 21, 22],\n",
            "        [18, 19, 20],\n",
            "        [ 2,  2,  6],\n",
            "        [ 9,  4,  5]])\n",
            "Batch target: tensor([ 2,  6, 16,  2])\n",
            "Batch context: tensor([[ 6, 16, 17],\n",
            "        [ 5, 13,  3],\n",
            "        [ 2,  2, 12],\n",
            "        [20,  6, 21]])\n",
            "Batch target: tensor([18, 14,  4, 22])\n",
            "Batch context: tensor([[17, 18, 19],\n",
            "        [ 2,  2,  7],\n",
            "        [ 8,  3,  9],\n",
            "        [ 4,  5, 13]])\n",
            "Batch target: tensor([20,  8,  4,  3])\n",
            "Batch context: tensor([[ 2,  2,  2],\n",
            "        [19, 20,  6],\n",
            "        [ 2,  6, 16],\n",
            "        [16, 17, 18]])\n",
            "Batch target: tensor([12, 21, 17, 19])\n",
            "Batch context: tensor([[ 2,  2,  2],\n",
            "        [ 2,  7,  8],\n",
            "        [12,  4,  5],\n",
            "        [ 2, 12,  4]])\n",
            "Batch target: tensor([ 2,  3, 13,  5])\n",
            "Batch context: tensor([[ 2,  2,  2],\n",
            "        [ 3,  9,  4],\n",
            "        [ 3, 14, 15],\n",
            "        [ 7,  8,  3]])\n",
            "Batch target: tensor([6, 5, 2, 9])\n",
            "Batch context: tensor([[13,  3, 14],\n",
            "        [ 2,  2,  2]])\n",
            "Batch target: tensor([15,  7])\n",
            "19.017954652765063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting the word embeddings"
      ],
      "metadata": {
        "id": "ggDBCb0fZMNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbors(emb, voc, inv_voc, word, n_neighbors=5):\n",
        "\n",
        "    # Look up the embedding for the test word.\n",
        "    test_emb = emb.weight[voc[word]]\n",
        "\n",
        "    # We'll use a cosine similarity function to find the most similar words.\n",
        "    sim_func = nn.CosineSimilarity(dim=1)\n",
        "    cosine_scores = sim_func(test_emb, emb.weight)\n",
        "\n",
        "    # Find the positions of the highest cosine values.\n",
        "    near_nbr = cosine_scores.topk(n_neighbors+1)\n",
        "    topk_cos = near_nbr.values[1:]\n",
        "    topk_indices = near_nbr.indices[1:]\n",
        "    # NB: the first word in the top-k list is the query word itself!\n",
        "    # That's why we skip the first position in the code above.\n",
        "\n",
        "    # Finally, map word indices back to strings, and put the result in a list.\n",
        "    return [ (inv_voc[ix.item()], cos.item()) for ix, cos in zip(topk_indices, topk_cos) ]\n",
        "\n",
        "nearest_neighbors(\"sweden\")\n",
        "nearest_neighbors(\"2005\")"
      ],
      "metadata": {
        "id": "lxQFbdXMZLmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_embeddings_pca(emb, inv_voc, words):\n",
        "    vectors = np.vstack([emb.weight[inv_voc[w]].cpu().detach().numpy() for w in words])\n",
        "    vectors -= vectors.mean(axis=0)\n",
        "    twodim = TruncatedSVD(n_components=2).fit_transform(vectors)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, twodim):\n",
        "        plt.text(x+0.02, y, word)\n",
        "    plt.axis('off')\n",
        "\n",
        "plot_embeddings_pca(model[0], prepr, ['sweden', 'denmark', 'europe', 'africa', 'london', 'stockholm', 'large', 'small', 'great', 'black', '3', '7', '10', 'seven', 'three', 'ten', '1984', '2005', '2010'])"
      ],
      "metadata": {
        "id": "pYxSMQvnZTVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}