{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiTheGreat/Intro-to-language-modeling/blob/main/modified_intro_to_language_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Preparations"
      ],
      "metadata": {
        "id": "Ash16YV-b6T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahdiTheGreat/Intro-to-language-modeling.git\n",
        "%cd Intro-to-language-modeling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXuQ-VlzuRv",
        "outputId": "c8e39800-a605-4802-8943-9b7776605bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Intro-to-language-modeling'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 61 (delta 32), reused 2 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (61/61), 30.34 MiB | 16.03 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "/content/Intro-to-language-modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fv9gQcVafW3"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import spacy\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=2024):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(1998)"
      ],
      "metadata": {
        "id": "Qjj4IdOi08ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to plot the training metrics\n",
        "\n",
        "def plot_training_metrics(train_acc, val_acc, train_loss, title, save_path):\n",
        "    # Ensure that all input lists have the same length\n",
        "    assert len(train_acc) == len(val_acc) == len(train_loss), \"All input histories must have the same length.\"\n",
        "\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "    # Create the metrics DataFrame\n",
        "    df_metrics = pd.DataFrame({\n",
        "        'Epoch': epochs,\n",
        "        'Training Accuracy (%)': train_acc,\n",
        "        'Validation Accuracy (%)': val_acc,\n",
        "        'Training Loss': train_loss\n",
        "    })\n",
        "\n",
        "    # Initialize the plot\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Training and Validation Accuracy on ax1\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy (%)', color=color)\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Training Accuracy (%)'], label='Train Acc', color='tab:blue')\n",
        "    ax1.plot(df_metrics['Epoch'], df_metrics['Validation Accuracy (%)'], label='Val Acc', color='tab:cyan')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Create a second y-axis for Training Loss\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Loss', color=color)\n",
        "    ax2.plot(df_metrics['Epoch'], df_metrics['Training Loss'], label='Train Loss', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Combine legends from both axes\n",
        "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
        "\n",
        "    # Set plot title and layout\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and display the plot\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TDDGQTI51AF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEDybdl906rv",
        "outputId": "fcf03d02-2b45-4c5f-b2df-e46bb0542d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 & 2"
      ],
      "metadata": {
        "id": "8VLcOGFvb-pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset='lmdemo'\n",
        "zip_file = f\"{dataset}.zip\"\n",
        "!unzip -q $zip_file\n",
        "!rm $zip_file"
      ],
      "metadata": {
        "id": "IE8oAx8b3AWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set=open(f'{dataset}/train.txt','r',encoding='utf-8').read()\n",
        "val_set=open(f'{dataset}/val.txt','r',encoding='utf-8').read()"
      ],
      "metadata": {
        "id": "clFRaGPQ4Jc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize data\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "HJ_uX3IDof2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_filepath=\"example.txt\""
      ],
      "metadata": {
        "id": "0YlBHofdlJsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "\n",
        "def get_token_counter(filepath,nlp,encoding):\n",
        "\n",
        "    buffer = \"\"  # Buffer to store partial sentences between lines\n",
        "    token_counter = Counter()\n",
        "\n",
        "    def sent_processor(sent,complete=True):\n",
        "     tokens=[]\n",
        "     if complete: tokens.append(nlp(\"BEGINNING\")[0])  # Add \"BEGINNING\" at the start of each sentence\n",
        "     tokens.extend([token for token in sent])  # Add sentence tokens\n",
        "     if complete: tokens.append(nlp(\"END\")[0])  # Add \"END\" at the end of each sentence\n",
        "     for token in tokens:\n",
        "      if not token.is_space:\n",
        "       token_counter[token.text.lower()] += 1\n",
        "\n",
        "\n",
        "    with open(filepath, 'r') as file:\n",
        "\n",
        "\n",
        "        for line in file:\n",
        "            # Add line to buffer and process with spaCy\n",
        "            buffer += \" \" + line.strip()\n",
        "            doc = nlp(buffer)\n",
        "            # Extract complete sentences\n",
        "            sentences = list(doc.sents)\n",
        "            for i, sent in enumerate(sentences):\n",
        "                # If it's not the last sentence, we print it as it's complete\n",
        "                if i < len(sentences) - 1:\n",
        "                    print(sent)\n",
        "                    sent_processor(sent)\n",
        "                else:\n",
        "                    # If it's the last sentence, store it in the buffer in case it's incomplete\n",
        "                    buffer = sent.text\n",
        "                    # Process sentences and identify complete sentences\n",
        "            for sent in doc.sents:\n",
        "                if sent.end_char < len(buffer):\n",
        "                    print(sent)\n",
        "                    sent_processor(sent)\n",
        "\n",
        "        # Process any remaining content in the buffer\n",
        "        doc = nlp(buffer)\n",
        "        for sent in doc.sents:\n",
        "         print(sent)\n",
        "         sent_processor(sent)\n",
        "\n",
        "    return token_counter\n",
        "\n",
        "# Load spaCy model for tokenization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class VocabularyBuilder:\n",
        "    def __init__(self, max_voc_size=None):\n",
        "        self.max_voc_size = max_voc_size\n",
        "        self.str_to_int = {}\n",
        "        self.int_to_str = {}\n",
        "        self.special_tokens = [\"BEGINNING\", \"END\", \"UNKNOWN\"]\n",
        "        self.token_counter = None\n",
        "\n",
        "\n",
        "    def build_vocabulary(self, filepath, nlp,token_counter_savepath=None,token_counter_loadpath=None,encoding=\"utf-8\"):\n",
        "\n",
        "        # Tokenize text and count tokens\n",
        "        if token_counter_loadpath is not None:\n",
        "         with open(token_counter_loadpath, \"r\") as file:\n",
        "            self.token_counter = Counter(json.load(file))\n",
        "        else:\n",
        "         self.token_counter =get_token_counter(filepath=filepath,nlp=nlp,encoding=encoding)\n",
        "\n",
        "        # Start vocabulary with special tokens\n",
        "        for idx, token in enumerate(self.special_tokens):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        # Select the most common tokens, considering max_voc_size - len(special_tokens)\n",
        "        if self.max_voc_size is None:\n",
        "            max_words = len(self.token_counter) - len(self.special_tokens)\n",
        "            self.max_voc_size = max_words + len(self.special_tokens)\n",
        "        else:\n",
        "         max_words = self.max_voc_size - len(self.special_tokens)\n",
        "        most_common_tokens = self.token_counter.most_common(max_words)\n",
        "\n",
        "        for idx, (token, _) in enumerate(most_common_tokens, start=len(self.special_tokens)):\n",
        "            self.str_to_int[token] = idx\n",
        "            self.int_to_str[idx] = token\n",
        "\n",
        "        # Save to a JSON file\n",
        "        if token_counter_savepath is not None:\n",
        "         with open(token_counter_savepath, \"w\") as file:\n",
        "             json.dump(self.token_counter, file)\n",
        "\n",
        "\n",
        "    def get_token_id(self, token):\n",
        "        # Return the integer ID for a given token\n",
        "        return self.str_to_int.get(token.lower(), self.str_to_int[\"UNKNOWN\"])\n",
        "\n",
        "    def get_token_str(self, token_id):\n",
        "        # Return the original token string for a given integer ID\n",
        "        return self.int_to_str.get(token_id, \"UNKNOWN\")\n",
        "\n",
        "    def add_special_tokens_to_text(self, text):\n",
        "        \"\"\"\n",
        "        Tokenizes the text by sentence and adds special 'BEGINNING' and 'END' tokens\n",
        "        around each sentence.\n",
        "\n",
        "        Parameters:\n",
        "        - text (str): The input text.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of tokens with special 'BEGINNING' and 'END' tokens added.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    def sanity_check(self):\n",
        "        # Check vocabulary size\n",
        "        assert len(self.str_to_int) <= self.max_voc_size, \"Vocabulary size exceeds max_voc_size.\"\n",
        "\n",
        "        # Check special tokens exist and are unique\n",
        "        for token in self.special_tokens:\n",
        "            assert token in self.str_to_int, f\"Missing special token: {token}\"\n",
        "\n",
        "        # Check if highly frequent words are included and rare ones are not\n",
        "        common_words = [\"the\", \"and\"]\n",
        "        rare_words = [\"cuboidal\", \"epiglottis\"]\n",
        "\n",
        "        for word in common_words:\n",
        "            assert word in self.str_to_int, f\"Common word '{word}' not in vocabulary.\"\n",
        "\n",
        "        for word in rare_words:\n",
        "            assert word not in self.str_to_int, f\"Rare word '{word}' should not be in vocabulary.\"\n",
        "\n",
        "        # Check that mapping back and forth works for a test word\n",
        "        test_word = \"The\"\n",
        "        token_id = self.get_token_id(test_word)\n",
        "        assert self.get_token_str(token_id) == test_word.lower(), \"Round-trip token mapping failed.\"\n",
        "\n",
        "        print(\"Sanity check passed!\")\n",
        "\n",
        "token_counter_filepath=\"token_counter.json\"\n",
        "vocab_builder = VocabularyBuilder()\n",
        "vocab_builder.build_vocabulary(filepath=example_filepath, nlp=nlp,token_counter_savepath=token_counter_filepath)\n",
        "\n",
        "# Example mappings\n",
        "print(\"str_to_int:\", vocab_builder.str_to_int)\n",
        "print(\"int_to_str:\", vocab_builder.int_to_str)\n",
        "print(\"vocabulary size: \",len(vocab_builder.token_counter))\n",
        "\n",
        "# Convert a token to integer ID and back to string\n",
        "token_id = vocab_builder.get_token_id(\"example\")\n",
        "print(\"Token ID for 'example':\", token_id)\n",
        "print(\"Original token from ID:\", vocab_builder.get_token_str(token_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzu9MwAtlMHS",
        "outputId": "59f00408-fd28-4261-c06f-199d35aa352c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Anatomy Anatomy (Greek anatomē, “dissection”) is the branch of biology concerned with the study of the structure of organisms and their parts.  \n",
            "Anatomy is a branch of natural science dealing with the structural organization of living things.  \n",
            "It is an old science, having its beginnings in prehistoric times.  \n",
            "Anatomy is inherently tied to embryology, comparative anatomy, evolutionary biology, and phylogeny, as these are the processes by which anatomy is generated over immediate (embryology) and long (evolution) timescales.  \n",
            "Human anatomy is one of the basic essential sciences of medicine.\n",
            "The discipline of anatomy is divided into macroscopic and microscopic anatomy.  \n",
            "Macroscopic anatomy, or gross anatomy, is the examination of an animal's body parts using unaided eyesight.  \n",
            "Gross anatomy also includes the branch of superficial anatomy.  \n",
            "Human anatomy is one of the basic essential sciences of medicine.\n",
            "The discipline of anatomy is divided into macroscopic and microscopic anatomy.  \n",
            "Microscopic anatomy involves the use of optical instruments in the study of the tissues of various structures, known as histology, and also in the study of cells.\n",
            "str_to_int: {'BEGINNING': 0, 'END': 1, 'UNKNOWN': 2, 'anatomy': 3, 'of': 4, 'the': 5, 'beginning': 6, '.': 7, 'end': 8, ',': 9, 'is': 10, 'and': 11, '(': 12, ')': 13, 'branch': 14, 'study': 15, 'in': 16, 'macroscopic': 17, 'microscopic': 18, 'biology': 19, 'with': 20, 'parts': 21, 'science': 22, 'an': 23, 'embryology': 24, 'as': 25, 'human': 26, 'one': 27, 'basic': 28, 'essential': 29, 'sciences': 30, 'medicine': 31, 'discipline': 32, 'divided': 33, 'into': 34, 'gross': 35, 'also': 36, 'greek': 37, 'anatomē': 38, '“': 39, 'dissection': 40, '”': 41, 'concerned': 42, 'structure': 43, 'organisms': 44, 'their': 45, 'a': 46, 'natural': 47, 'dealing': 48, 'structural': 49, 'organization': 50, 'living': 51, 'things': 52, 'it': 53, 'old': 54, 'having': 55, 'its': 56, 'beginnings': 57, 'prehistoric': 58, 'times': 59, 'inherently': 60, 'tied': 61, 'to': 62, 'comparative': 63, 'evolutionary': 64, 'phylogeny': 65, 'these': 66, 'are': 67, 'processes': 68, 'by': 69, 'which': 70, 'generated': 71, 'over': 72, 'immediate': 73, 'long': 74, 'evolution': 75, 'timescales': 76, 'or': 77, 'examination': 78, 'animal': 79, \"'s\": 80, 'body': 81, 'using': 82, 'unaided': 83, 'eyesight': 84, 'includes': 85, 'superficial': 86, 'involves': 87, 'use': 88, 'optical': 89, 'instruments': 90, 'tissues': 91, 'various': 92, 'structures': 93}\n",
            "int_to_str: {0: 'BEGINNING', 1: 'END', 2: 'UNKNOWN', 3: 'anatomy', 4: 'of', 5: 'the', 6: 'beginning', 7: '.', 8: 'end', 9: ',', 10: 'is', 11: 'and', 12: '(', 13: ')', 14: 'branch', 15: 'study', 16: 'in', 17: 'macroscopic', 18: 'microscopic', 19: 'biology', 20: 'with', 21: 'parts', 22: 'science', 23: 'an', 24: 'embryology', 25: 'as', 26: 'human', 27: 'one', 28: 'basic', 29: 'essential', 30: 'sciences', 31: 'medicine', 32: 'discipline', 33: 'divided', 34: 'into', 35: 'gross', 36: 'also', 37: 'greek', 38: 'anatomē', 39: '“', 40: 'dissection', 41: '”', 42: 'concerned', 43: 'structure', 44: 'organisms', 45: 'their', 46: 'a', 47: 'natural', 48: 'dealing', 49: 'structural', 50: 'organization', 51: 'living', 52: 'things', 53: 'it', 54: 'old', 55: 'having', 56: 'its', 57: 'beginnings', 58: 'prehistoric', 59: 'times', 60: 'inherently', 61: 'tied', 62: 'to', 63: 'comparative', 64: 'evolutionary', 65: 'phylogeny', 66: 'these', 67: 'are', 68: 'processes', 69: 'by', 70: 'which', 71: 'generated', 72: 'over', 73: 'immediate', 74: 'long', 75: 'evolution', 76: 'timescales', 77: 'or', 78: 'examination', 79: 'animal', 80: \"'s\", 81: 'body', 82: 'using', 83: 'unaided', 84: 'eyesight', 85: 'includes', 86: 'superficial', 87: 'involves', 88: 'use', 89: 'optical', 90: 'instruments', 91: 'tissues', 92: 'various', 93: 'structures'}\n",
            "vocabulary size:  94\n",
            "Token ID for 'example': 2\n",
            "Original token from ID: UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_counter_filepath=\"token_counter.json\"\n",
        "vocab_builder = VocabularyBuilder()\n",
        "vocab_builder.build_vocabulary(filepath=example_filepath, nlp=nlp,token_counter_loadpath=token_counter_filepath)\n",
        "\n",
        "# Example mappings\n",
        "print(\"str_to_int:\", vocab_builder.str_to_int)\n",
        "print(\"int_to_str:\", vocab_builder.int_to_str)\n",
        "print(\"vocabulary size: \",len(vocab_builder.token_counter))\n",
        "\n",
        "\n",
        "# Convert a token to integer ID and back to string\n",
        "token_id = vocab_builder.get_token_id(\"example\")\n",
        "print(\"Token ID for 'example':\", token_id)\n",
        "print(\"Original token from ID:\", vocab_builder.get_token_str(token_id))"
      ],
      "metadata": {
        "id": "T1LhuLzfE2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36307ce-153a-46e2-fc3d-5234eb998d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "str_to_int: {'BEGINNING': 0, 'END': 1, 'UNKNOWN': 2, 'anatomy': 3, 'of': 4, 'the': 5, 'beginning': 6, '.': 7, 'end': 8, ',': 9, 'is': 10, 'and': 11, '(': 12, ')': 13, 'branch': 14, 'study': 15, 'in': 16, 'macroscopic': 17, 'microscopic': 18, 'biology': 19, 'with': 20, 'parts': 21, 'science': 22, 'an': 23, 'embryology': 24, 'as': 25, 'human': 26, 'one': 27, 'basic': 28, 'essential': 29, 'sciences': 30, 'medicine': 31, 'discipline': 32, 'divided': 33, 'into': 34, 'gross': 35, 'also': 36, 'greek': 37, 'anatomē': 38, '“': 39, 'dissection': 40, '”': 41, 'concerned': 42, 'structure': 43, 'organisms': 44, 'their': 45, 'a': 46, 'natural': 47, 'dealing': 48, 'structural': 49, 'organization': 50, 'living': 51, 'things': 52, 'it': 53, 'old': 54, 'having': 55, 'its': 56, 'beginnings': 57, 'prehistoric': 58, 'times': 59, 'inherently': 60, 'tied': 61, 'to': 62, 'comparative': 63, 'evolutionary': 64, 'phylogeny': 65, 'these': 66, 'are': 67, 'processes': 68, 'by': 69, 'which': 70, 'generated': 71, 'over': 72, 'immediate': 73, 'long': 74, 'evolution': 75, 'timescales': 76, 'or': 77, 'examination': 78, 'animal': 79, \"'s\": 80, 'body': 81, 'using': 82, 'unaided': 83, 'eyesight': 84, 'includes': 85, 'superficial': 86, 'involves': 87, 'use': 88, 'optical': 89, 'instruments': 90, 'tissues': 91, 'various': 92, 'structures': 93}\n",
            "int_to_str: {0: 'BEGINNING', 1: 'END', 2: 'UNKNOWN', 3: 'anatomy', 4: 'of', 5: 'the', 6: 'beginning', 7: '.', 8: 'end', 9: ',', 10: 'is', 11: 'and', 12: '(', 13: ')', 14: 'branch', 15: 'study', 16: 'in', 17: 'macroscopic', 18: 'microscopic', 19: 'biology', 20: 'with', 21: 'parts', 22: 'science', 23: 'an', 24: 'embryology', 25: 'as', 26: 'human', 27: 'one', 28: 'basic', 29: 'essential', 30: 'sciences', 31: 'medicine', 32: 'discipline', 33: 'divided', 34: 'into', 35: 'gross', 36: 'also', 37: 'greek', 38: 'anatomē', 39: '“', 40: 'dissection', 41: '”', 42: 'concerned', 43: 'structure', 44: 'organisms', 45: 'their', 46: 'a', 47: 'natural', 48: 'dealing', 49: 'structural', 50: 'organization', 51: 'living', 52: 'things', 53: 'it', 54: 'old', 55: 'having', 56: 'its', 57: 'beginnings', 58: 'prehistoric', 59: 'times', 60: 'inherently', 61: 'tied', 62: 'to', 63: 'comparative', 64: 'evolutionary', 65: 'phylogeny', 66: 'these', 67: 'are', 68: 'processes', 69: 'by', 70: 'which', 71: 'generated', 72: 'over', 73: 'immediate', 74: 'long', 75: 'evolution', 76: 'timescales', 77: 'or', 78: 'examination', 79: 'animal', 80: \"'s\", 81: 'body', 82: 'using', 83: 'unaided', 84: 'eyesight', 85: 'includes', 86: 'superficial', 87: 'involves', 88: 'use', 89: 'optical', 90: 'instruments', 91: 'tissues', 92: 'various', 93: 'structures'}\n",
            "vocabulary size:  94\n",
            "Token ID for 'example': 2\n",
            "Original token from ID: UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform sanity check\n",
        "vocab_builder.sanity_check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1sB4W8Q0Qo9",
        "outputId": "21baa1c8-7e76-4afe-ce75-31081660d71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "class TrainingDataPreparer:\n",
        "    def __init__(self, vocab_builder, nlp, context_window_size=3, chunk_size=1024):\n",
        "        self.vocab_builder = vocab_builder\n",
        "        self.context_window_size = context_window_size\n",
        "        self.chunk_size = chunk_size\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def encode_token(self, token):\n",
        "        token_id = self.vocab_builder.get_token_id(token.text)\n",
        "        return token_id if token_id != self.vocab_builder.get_token_id(\"UNKNOWN\") else None\n",
        "\n",
        "    def prepare_training_data(self, input_file, output_file):\n",
        "        with open(input_file, \"r\") as infile, open(output_file, \"w\", newline=\"\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow([f\"Token_{i+1}\" for i in range(self.context_window_size)] + [\"Target\"])\n",
        "\n",
        "            # Initialize the beginning padding tokens\n",
        "            padded_tokens = [self.vocab_builder.get_token_id(\"BEGINNING\")] * self.context_window_size\n",
        "            first_chunk = True\n",
        "\n",
        "            while True:\n",
        "                chunk = infile.read(self.chunk_size)\n",
        "                if not chunk:\n",
        "                    break\n",
        "\n",
        "                # Tokenize chunk into sentences\n",
        "                doc = self.nlp(chunk)\n",
        "                sentences = list(doc.sents)\n",
        "\n",
        "                for sentence in sentences:\n",
        "                    # Process sentence and convert to token IDs, skipping unknowns and spaces\n",
        "                    sentence_token_ids = [\n",
        "                        self.encode_token(token) for token in sentence if self.encode_token(token) is not None\n",
        "                    ]\n",
        "\n",
        "                    if first_chunk and sentence_token_ids:\n",
        "                        padded_tokens += sentence_token_ids\n",
        "                        first_chunk = False\n",
        "                    else:\n",
        "                        # Add only the sentence tokens from subsequent sentences\n",
        "                        padded_tokens.extend(sentence_token_ids)\n",
        "\n",
        "                    # Add END token at the end of each sentence\n",
        "                    padded_tokens.append(self.vocab_builder.get_token_id(\"END\"))\n",
        "\n",
        "                    # Generate context-target sequences\n",
        "                    for i in range(len(padded_tokens) - self.context_window_size):\n",
        "                        context = padded_tokens[i:i + self.context_window_size]\n",
        "                        target = padded_tokens[i + self.context_window_size]\n",
        "                        writer.writerow(context + [target])\n",
        "\n",
        "                # Retain only the last context window tokens for the next chunk\n",
        "                padded_tokens = padded_tokens[-self.context_window_size:]\n",
        "\n",
        "        print(\"Training data preparation complete.\")\n",
        "\n",
        "    def print_csv_as_words(self, csv_file):\n",
        "           \"\"\"\n",
        "           Reads a CSV file with token IDs, decodes them to words, and prints each sequence.\n",
        "           \"\"\"\n",
        "           with open(csv_file, \"r\") as file:\n",
        "               reader = csv.reader(file)\n",
        "               headers = next(reader)  # Skip the header\n",
        "\n",
        "               for row in reader:\n",
        "                   context_ids = row[:-1]  # All columns except the last one are context\n",
        "                   target_id = row[-1]  # Last column is the target\n",
        "\n",
        "                   # Convert token IDs to words\n",
        "                   context_words = [self.vocab_builder.get_token_str(int(token_id)) for token_id in context_ids]\n",
        "                   target_word = self.vocab_builder.get_token_str(int(target_id))\n",
        "\n",
        "                   # Print context and target as words\n",
        "                   print(\"Context:\", context_words, \"-> Target:\", target_word)\n",
        "\n",
        "\n",
        "data_preparer = TrainingDataPreparer(vocab_builder=vocab_builder,nlp=nlp, context_window_size=3)\n",
        "\n",
        "input_file = \"example.txt\"\n",
        "output_file = \"training_sequences.csv\"\n",
        "\n",
        "# Prepare training data\n",
        "data_preparer.prepare_training_data(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "uXLrr6YeF0AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8959732-f603-4cf2-9d47-a1efd9db2988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=pd.read_csv(\"training_sequences.csv\")\n",
        "print(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIZFPXu6OacK",
        "outputId": "8b3fdb55-eb62-42e4-cc15-8920e0ae7ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Token_1  Token_2  Token_3  Target\n",
            "0          6        6        6       3\n",
            "1          6        6        3       3\n",
            "2          6        3        3      12\n",
            "3          3        3       12      37\n",
            "4          3       12       37      38\n",
            "..       ...      ...      ...     ...\n",
            "954       11       36       16       5\n",
            "955       36       16        5      15\n",
            "956       16        5       15       4\n",
            "957        5       15        4       7\n",
            "958       15        4        7       8\n",
            "\n",
            "[959 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_preparer.print_csv_as_words(\"training_sequences.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj9ZV2AgOdwC",
        "outputId": "dfa4491d-cddb-4840-a251-504d7face7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['eyesight', '.', 'end'] -> Target: gross\n",
            "Context: ['.', 'end', 'gross'] -> Target: anatomy\n",
            "Context: ['end', 'gross', 'anatomy'] -> Target: also\n",
            "Context: ['gross', 'anatomy', 'also'] -> Target: includes\n",
            "Context: ['anatomy', 'also', 'includes'] -> Target: the\n",
            "Context: ['also', 'includes', 'the'] -> Target: branch\n",
            "Context: ['includes', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: superficial\n",
            "Context: ['branch', 'of', 'superficial'] -> Target: anatomy\n",
            "Context: ['of', 'superficial', 'anatomy'] -> Target: .\n",
            "Context: ['superficial', 'anatomy', '.'] -> Target: end\n",
            "Context: ['beginning', 'beginning', 'beginning'] -> Target: anatomy\n",
            "Context: ['beginning', 'beginning', 'anatomy'] -> Target: anatomy\n",
            "Context: ['beginning', 'anatomy', 'anatomy'] -> Target: (\n",
            "Context: ['anatomy', 'anatomy', '('] -> Target: greek\n",
            "Context: ['anatomy', '(', 'greek'] -> Target: anatomē\n",
            "Context: ['(', 'greek', 'anatomē'] -> Target: ,\n",
            "Context: ['greek', 'anatomē', ','] -> Target: “\n",
            "Context: ['anatomē', ',', '“'] -> Target: dissection\n",
            "Context: [',', '“', 'dissection'] -> Target: ”\n",
            "Context: ['“', 'dissection', '”'] -> Target: )\n",
            "Context: ['dissection', '”', ')'] -> Target: is\n",
            "Context: ['”', ')', 'is'] -> Target: the\n",
            "Context: [')', 'is', 'the'] -> Target: branch\n",
            "Context: ['is', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: biology\n",
            "Context: ['branch', 'of', 'biology'] -> Target: concerned\n",
            "Context: ['of', 'biology', 'concerned'] -> Target: with\n",
            "Context: ['biology', 'concerned', 'with'] -> Target: the\n",
            "Context: ['concerned', 'with', 'the'] -> Target: study\n",
            "Context: ['with', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: structure\n",
            "Context: ['of', 'the', 'structure'] -> Target: of\n",
            "Context: ['the', 'structure', 'of'] -> Target: organisms\n",
            "Context: ['structure', 'of', 'organisms'] -> Target: and\n",
            "Context: ['of', 'organisms', 'and'] -> Target: their\n",
            "Context: ['organisms', 'and', 'their'] -> Target: parts\n",
            "Context: ['and', 'their', 'parts'] -> Target: .\n",
            "Context: ['their', 'parts', '.'] -> Target: end\n",
            "Context: ['parts', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: a\n",
            "Context: ['anatomy', 'is', 'a'] -> Target: branch\n",
            "Context: ['is', 'a', 'branch'] -> Target: of\n",
            "Context: ['a', 'branch', 'of'] -> Target: natural\n",
            "Context: ['branch', 'of', 'natural'] -> Target: science\n",
            "Context: ['of', 'natural', 'science'] -> Target: dealing\n",
            "Context: ['natural', 'science', 'dealing'] -> Target: with\n",
            "Context: ['science', 'dealing', 'with'] -> Target: the\n",
            "Context: ['dealing', 'with', 'the'] -> Target: structural\n",
            "Context: ['with', 'the', 'structural'] -> Target: organization\n",
            "Context: ['the', 'structural', 'organization'] -> Target: of\n",
            "Context: ['structural', 'organization', 'of'] -> Target: living\n",
            "Context: ['organization', 'of', 'living'] -> Target: things\n",
            "Context: ['of', 'living', 'things'] -> Target: .\n",
            "Context: ['living', 'things', '.'] -> Target: end\n",
            "Context: ['things', '.', 'end'] -> Target: it\n",
            "Context: ['.', 'end', 'it'] -> Target: is\n",
            "Context: ['end', 'it', 'is'] -> Target: an\n",
            "Context: ['it', 'is', 'an'] -> Target: old\n",
            "Context: ['is', 'an', 'old'] -> Target: science\n",
            "Context: ['an', 'old', 'science'] -> Target: ,\n",
            "Context: ['old', 'science', ','] -> Target: having\n",
            "Context: ['science', ',', 'having'] -> Target: its\n",
            "Context: [',', 'having', 'its'] -> Target: beginnings\n",
            "Context: ['having', 'its', 'beginnings'] -> Target: in\n",
            "Context: ['its', 'beginnings', 'in'] -> Target: prehistoric\n",
            "Context: ['beginnings', 'in', 'prehistoric'] -> Target: times\n",
            "Context: ['in', 'prehistoric', 'times'] -> Target: .\n",
            "Context: ['prehistoric', 'times', '.'] -> Target: end\n",
            "Context: ['times', '.', 'end'] -> Target: anatomy\n",
            "Context: ['.', 'end', 'anatomy'] -> Target: is\n",
            "Context: ['end', 'anatomy', 'is'] -> Target: inherently\n",
            "Context: ['anatomy', 'is', 'inherently'] -> Target: tied\n",
            "Context: ['is', 'inherently', 'tied'] -> Target: to\n",
            "Context: ['inherently', 'tied', 'to'] -> Target: embryology\n",
            "Context: ['tied', 'to', 'embryology'] -> Target: ,\n",
            "Context: ['to', 'embryology', ','] -> Target: comparative\n",
            "Context: ['embryology', ',', 'comparative'] -> Target: anatomy\n",
            "Context: [',', 'comparative', 'anatomy'] -> Target: ,\n",
            "Context: ['comparative', 'anatomy', ','] -> Target: evolutionary\n",
            "Context: ['anatomy', ',', 'evolutionary'] -> Target: biology\n",
            "Context: [',', 'evolutionary', 'biology'] -> Target: ,\n",
            "Context: ['evolutionary', 'biology', ','] -> Target: and\n",
            "Context: ['biology', ',', 'and'] -> Target: phylogeny\n",
            "Context: [',', 'and', 'phylogeny'] -> Target: ,\n",
            "Context: ['and', 'phylogeny', ','] -> Target: as\n",
            "Context: ['phylogeny', ',', 'as'] -> Target: these\n",
            "Context: [',', 'as', 'these'] -> Target: are\n",
            "Context: ['as', 'these', 'are'] -> Target: the\n",
            "Context: ['these', 'are', 'the'] -> Target: processes\n",
            "Context: ['are', 'the', 'processes'] -> Target: by\n",
            "Context: ['the', 'processes', 'by'] -> Target: which\n",
            "Context: ['processes', 'by', 'which'] -> Target: anatomy\n",
            "Context: ['by', 'which', 'anatomy'] -> Target: is\n",
            "Context: ['which', 'anatomy', 'is'] -> Target: generated\n",
            "Context: ['anatomy', 'is', 'generated'] -> Target: over\n",
            "Context: ['is', 'generated', 'over'] -> Target: immediate\n",
            "Context: ['generated', 'over', 'immediate'] -> Target: (\n",
            "Context: ['over', 'immediate', '('] -> Target: embryology\n",
            "Context: ['immediate', '(', 'embryology'] -> Target: )\n",
            "Context: ['(', 'embryology', ')'] -> Target: and\n",
            "Context: ['embryology', ')', 'and'] -> Target: long\n",
            "Context: [')', 'and', 'long'] -> Target: (\n",
            "Context: ['and', 'long', '('] -> Target: evolution\n",
            "Context: ['long', '(', 'evolution'] -> Target: )\n",
            "Context: ['(', 'evolution', ')'] -> Target: timescales\n",
            "Context: ['evolution', ')', 'timescales'] -> Target: .\n",
            "Context: [')', 'timescales', '.'] -> Target: end\n",
            "Context: ['timescales', '.', 'end'] -> Target: human\n",
            "Context: ['.', 'end', 'human'] -> Target: anatomy\n",
            "Context: ['end', 'human', 'anatomy'] -> Target: is\n",
            "Context: ['human', 'anatomy', 'is'] -> Target: one\n",
            "Context: ['anatomy', 'is', 'one'] -> Target: of\n",
            "Context: ['is', 'one', 'of'] -> Target: the\n",
            "Context: ['one', 'of', 'the'] -> Target: basic\n",
            "Context: ['of', 'the', 'basic'] -> Target: essential\n",
            "Context: ['the', 'basic', 'essential'] -> Target: sciences\n",
            "Context: ['basic', 'essential', 'sciences'] -> Target: of\n",
            "Context: ['essential', 'sciences', 'of'] -> Target: medicine\n",
            "Context: ['sciences', 'of', 'medicine'] -> Target: .\n",
            "Context: ['of', 'medicine', '.'] -> Target: end\n",
            "Context: ['medicine', '.', 'end'] -> Target: the\n",
            "Context: ['.', 'end', 'the'] -> Target: discipline\n",
            "Context: ['end', 'the', 'discipline'] -> Target: of\n",
            "Context: ['the', 'discipline', 'of'] -> Target: anatomy\n",
            "Context: ['discipline', 'of', 'anatomy'] -> Target: is\n",
            "Context: ['of', 'anatomy', 'is'] -> Target: divided\n",
            "Context: ['anatomy', 'is', 'divided'] -> Target: into\n",
            "Context: ['is', 'divided', 'into'] -> Target: macroscopic\n",
            "Context: ['divided', 'into', 'macroscopic'] -> Target: and\n",
            "Context: ['into', 'macroscopic', 'and'] -> Target: microscopic\n",
            "Context: ['macroscopic', 'and', 'microscopic'] -> Target: anatomy\n",
            "Context: ['and', 'microscopic', 'anatomy'] -> Target: .\n",
            "Context: ['microscopic', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: macroscopic\n",
            "Context: ['.', 'end', 'macroscopic'] -> Target: anatomy\n",
            "Context: ['end', 'macroscopic', 'anatomy'] -> Target: ,\n",
            "Context: ['macroscopic', 'anatomy', ','] -> Target: or\n",
            "Context: ['anatomy', ',', 'or'] -> Target: gross\n",
            "Context: [',', 'or', 'gross'] -> Target: anatomy\n",
            "Context: ['or', 'gross', 'anatomy'] -> Target: ,\n",
            "Context: ['gross', 'anatomy', ','] -> Target: is\n",
            "Context: ['anatomy', ',', 'is'] -> Target: the\n",
            "Context: [',', 'is', 'the'] -> Target: examination\n",
            "Context: ['is', 'the', 'examination'] -> Target: of\n",
            "Context: ['the', 'examination', 'of'] -> Target: an\n",
            "Context: ['examination', 'of', 'an'] -> Target: animal\n",
            "Context: ['of', 'an', 'animal'] -> Target: 's\n",
            "Context: ['an', 'animal', \"'s\"] -> Target: body\n",
            "Context: ['animal', \"'s\", 'body'] -> Target: parts\n",
            "Context: [\"'s\", 'body', 'parts'] -> Target: using\n",
            "Context: ['body', 'parts', 'using'] -> Target: unaided\n",
            "Context: ['parts', 'using', 'unaided'] -> Target: eyesight\n",
            "Context: ['using', 'unaided', 'eyesight'] -> Target: .\n",
            "Context: ['unaided', 'eyesight', '.'] -> Target: end\n",
            "Context: ['eyesight', '.', 'end'] -> Target: gross\n",
            "Context: ['.', 'end', 'gross'] -> Target: anatomy\n",
            "Context: ['end', 'gross', 'anatomy'] -> Target: also\n",
            "Context: ['gross', 'anatomy', 'also'] -> Target: includes\n",
            "Context: ['anatomy', 'also', 'includes'] -> Target: the\n",
            "Context: ['also', 'includes', 'the'] -> Target: branch\n",
            "Context: ['includes', 'the', 'branch'] -> Target: of\n",
            "Context: ['the', 'branch', 'of'] -> Target: superficial\n",
            "Context: ['branch', 'of', 'superficial'] -> Target: anatomy\n",
            "Context: ['of', 'superficial', 'anatomy'] -> Target: .\n",
            "Context: ['superficial', 'anatomy', '.'] -> Target: end\n",
            "Context: ['anatomy', '.', 'end'] -> Target: microscopic\n",
            "Context: ['.', 'end', 'microscopic'] -> Target: anatomy\n",
            "Context: ['end', 'microscopic', 'anatomy'] -> Target: involves\n",
            "Context: ['microscopic', 'anatomy', 'involves'] -> Target: the\n",
            "Context: ['anatomy', 'involves', 'the'] -> Target: use\n",
            "Context: ['involves', 'the', 'use'] -> Target: of\n",
            "Context: ['the', 'use', 'of'] -> Target: optical\n",
            "Context: ['use', 'of', 'optical'] -> Target: instruments\n",
            "Context: ['of', 'optical', 'instruments'] -> Target: in\n",
            "Context: ['optical', 'instruments', 'in'] -> Target: the\n",
            "Context: ['instruments', 'in', 'the'] -> Target: study\n",
            "Context: ['in', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: the\n",
            "Context: ['study', 'of', 'the'] -> Target: tissues\n",
            "Context: ['of', 'the', 'tissues'] -> Target: of\n",
            "Context: ['the', 'tissues', 'of'] -> Target: various\n",
            "Context: ['tissues', 'of', 'various'] -> Target: structures\n",
            "Context: ['of', 'various', 'structures'] -> Target: ,\n",
            "Context: ['various', 'structures', ','] -> Target: as\n",
            "Context: ['structures', ',', 'as'] -> Target: ,\n",
            "Context: [',', 'as', ','] -> Target: and\n",
            "Context: ['as', ',', 'and'] -> Target: also\n",
            "Context: [',', 'and', 'also'] -> Target: in\n",
            "Context: ['and', 'also', 'in'] -> Target: the\n",
            "Context: ['also', 'in', 'the'] -> Target: study\n",
            "Context: ['in', 'the', 'study'] -> Target: of\n",
            "Context: ['the', 'study', 'of'] -> Target: .\n",
            "Context: ['study', 'of', '.'] -> Target: end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a tensor dataset ##\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def TorchDataLoader(training_sequences, batch_size):\n",
        "  context_words = [item[0] for item in training_sequences]  # List of [context]\n",
        "  target_words = [item[1] for item in training_sequences]   # List of target words\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  context_tensor = torch.tensor(context_words, dtype=torch.long)  # Shape: (num_samples, 3)\n",
        "  target_tensor = torch.tensor(target_words, dtype=torch.long)    # Shape: (num_samples,)\n",
        "\n",
        "  # Create a TensorDataset\n",
        "  dataset = TensorDataset(context_tensor, target_tensor)\n",
        "\n",
        "  # Create a DataLoader for batching\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "DqKicZuza81v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3"
      ],
      "metadata": {
        "id": "6cxG6iHlclgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# EarlyStopping class remains the same\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, verbose=False, path='checkpoint.pth'):\n",
        "        self.patience = patience  # Number of epochs to wait for improvement\n",
        "        self.delta = delta  # Minimum change to qualify as an improvement\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.path = path  # Path to save the best model\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss < self.best_score - self.delta:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Save model when validation loss decreases.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "class SimpleANN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, layer_sizes,activation=nn.ReLU,last_layer_activation=nn.Softmax,dropout=0):\n",
        "\n",
        "        super(SimpleANN, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(len(layer_sizes)-2):\n",
        "          self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
        "          self.layers.append(nn.Dropout(dropout))\n",
        "          self.layers.append(activation())\n",
        "\n",
        "        self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1]))\n",
        "        if last_layer_activation is not None:\n",
        "         self.layers.append(nn.Dropout(dropout))\n",
        "         self.layers.append(last_layer_activation())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Assuming x is a batch of word indices (e.g., [batch_size])\n",
        "        embeddings = self.embeddings(x)  # Get word embeddings for each word in the batch\n",
        "\n",
        "        # Flatten the input embeddings (if necessary, depending on your task)\n",
        "        x = embeddings.view(-1, np.prod(embeddings.shape[1:]))  # Flatten for fully connected layers\n",
        "\n",
        "        #x = x.view(-1, np.prod(x.shape[1:])) # Flatten the input\n",
        "        x = x.float()\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Q2CkGhOV1JpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleANN(layer_sizes=[48, 64, 65000], vocab_size=65000, embed_size=16)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "patience = 5\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "number_of_epochs = 10\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "    print(f\"--- Epoch {epoch+1}/{number_of_epochs} ---\")\n",
        "    for batch_context, batch_target in tqdm(trainloader):\n",
        "        #FORWARD PASS:\n",
        "        X = batch_context\n",
        "        Y = batch_target\n",
        "        X, Y = X.to(device), Y.to(device)\n",
        "        outputs = model(X)  # Model output for X\n",
        "        loss = criterion(outputs, Y) # Compute the loss between model output and Y\n",
        "\n",
        "        #BACKWARD PASS (updating the model parameters):\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()        # Compute gradients\n",
        "        optimizer.step()       # Update model parameters\n",
        "\n",
        "    print(f\"Training perplexity: {np.exp(loss.item()):.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():  # No gradient computation for validation\n",
        "        for inputs, targets in valloader:\n",
        "            X = inputs\n",
        "            Y = targets\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, Y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(valloader)  # Average validation loss\n",
        "    print(f\"Validation perplexity: {np.exp(avg_val_loss):.6f}\")\n",
        "\n",
        "    # Call early stopping after each epoch\n",
        "    early_stopping(avg_val_loss, model)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "# Optionally, load the best model after training\n",
        "model.load_state_dict(torch.load('checkpoint.pth'))"
      ],
      "metadata": {
        "id": "7iUtwI8nbBO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d329cfb7-0eeb-4990-d635-10d29e42f634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/10 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-68ddda73f100>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Epoch {epoch+1}/{number_of_epochs} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#FORWARD PASS:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "Hsm3CLoWgub5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\"This is very\",\n",
        "                  \"A tall building\",\n",
        "                  \"The next sentence\",\n",
        "                  \"Not a big\"]\n",
        "\n",
        "encoded_sentences = []\n",
        "for sentence in test_sentences:\n",
        "  encoded_sentences.append([vocab_builder.get_token_id(sentence) for word in sentence.split(\" \")])\n",
        "\n",
        "output = model(torch.tensor(encoded_sentences)).detach().numpy()\n",
        "\n",
        "# Predict\n",
        "predictions = np.argmax(output, axis=1)\n",
        "\n",
        "for prediction in predictions:\n",
        "  print(vocab_builder.get_token_str(prediction))"
      ],
      "metadata": {
        "id": "HOp6TdEPgtmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = np.exp(avg_val_loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "id": "lb9-NZAhzYLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbors(emb, voc, word, n_neighbors=5):\n",
        "\n",
        "    # Look up the embedding for the test word.\n",
        "    test_emb = emb.weight[voc.get_token_id(word)]\n",
        "\n",
        "    # We'll use a cosine similarity function to find the most similar words.\n",
        "    sim_func = nn.CosineSimilarity(dim=1)\n",
        "    cosine_scores = sim_func(test_emb, emb.weight)\n",
        "\n",
        "    # Find the positions of the highest cosine values.\n",
        "    near_nbr = cosine_scores.topk(n_neighbors+1)\n",
        "    topk_cos = near_nbr.values[1:]\n",
        "    topk_indices = near_nbr.indices[1:]\n",
        "    # NB: the first word in the top-k list is the query word itself!\n",
        "    # That's why we skip the first position in the code above.\n",
        "\n",
        "    # Finally, map word indices back to strings, and put the result in a list.\n",
        "    return [ (voc.get_token_str(ix.item()), cos.item()) for ix, cos in zip(topk_indices, topk_cos) ]\n",
        "\n",
        "nearest_neighbors(model.embeddings, vocab_builder, \"sweden\")\n",
        "nearest_neighbors(model.embeddings, vocab_builder, \"2005\")"
      ],
      "metadata": {
        "id": "Vm5IGathjhMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_embeddings_pca(emb, voc, words):\n",
        "    vectors = np.vstack([emb.weight[voc.get_token_id(w)].cpu().detach().numpy() for w in words])\n",
        "    vectors -= vectors.mean(axis=0)\n",
        "    twodim = TruncatedSVD(n_components=2).fit_transform(vectors)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, twodim):\n",
        "        plt.text(x+0.02, y, word)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_embeddings_pca(model.embeddings, vocab_builder, ['sweden', 'denmark', 'europe', 'africa', 'london', 'stockholm', 'large', 'small', 'great', 'black', '3', '7', '10', 'seven', 'three', 'ten', '1984', '2005', '2010'])\n"
      ],
      "metadata": {
        "id": "RpQwos6mj8di"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}